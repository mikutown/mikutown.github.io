{"title":"MAPPO源代码分析","slug":"MAPPO源代码分析","date":"2022-09-30T10:22:03.000Z","updated":"2022-10-03T08:53:15.355Z","comments":true,"path":"api/articles/MAPPO源代码分析.json","excerpt":"代码地址：https://github.com/marlbenchmark/on-policy官方出品轻量化mappo代码：https://github.com/tinyzqh/light_mappo对应论文：The Surprising Effectiveness of MAPPO in Cooperative, Multi-Agent Games","covers":["http://cdn.leafii.top/img/mappo.png"],"content":"<p>代码地址：<a href=\"https://github.com/marlbenchmark/on-policy\">https://github.com/marlbenchmark/on-policy</a></p>\n<p>官方出品轻量化mappo代码：<a href=\"https://github.com/tinyzqh/light_mappo\">https://github.com/tinyzqh/light_mappo</a></p>\n<p>对应论文：The Surprising Effectiveness of MAPPO in Cooperative, Multi-Agent Games</p>\n<span id=\"more\"></span>\n\n<h2 id=\"代码运行\"><a href=\"#代码运行\" class=\"headerlink\" title=\"代码运行\"></a>代码运行</h2><p>使用conda新建环境，python版本推荐为3.6.7，并且安装readme中的MPE环境，然后将pycharm中train_mpe.py文件的configuration中的参数设置为<code>--env_name &quot;MPE&quot; --algorithm_name &quot;rmappo&quot; --experiment_name &quot;check&quot; --scenario_name &quot;simple_spread&quot; --num_agents 3 --num_landmarks 3 --seed 1 --n_training_threads 1 --n_rollout_threads 4 --num_mini_batch 1 --episode_length 25 --num_env_steps 10000 --ppo_epoch 10 --use_ReLU --gain 0.01 --lr 7e-4 --critic_lr 7e-4 --wandb_name &quot;leafii&quot; --user_name &quot;leafii&quot;</code>，以免因为电脑配置不足无法运行。安装其他包时要参考文件夹中requirement.txt中的版本，以免由于版本兼容问题造成代码无法正常运行，debug。</p>\n<h3 id=\"MAPPO算法伪代码\"><a href=\"#MAPPO算法伪代码\" class=\"headerlink\" title=\"MAPPO算法伪代码\"></a>MAPPO算法伪代码</h3><p><img src=\"http://cdn.leafii.top/img/mappo.png\" alt=\"img\" loading=\"lazy\"></p>\n<p>有两个网络，分别是策略$\\pi_{\\theta}$和值函数$V_{\\phi}$。（作者在文中说如果智能体是同种类的就采用相同的网络参数，对于每个智能体内部也可以采用各自的actor和critic网络，为了符号的便利性，作者直接使用一个网络参数来表示）。值函数$V_{\\phi}$需要学习一个映射： $S \\rightarrow \\mathbb R$。策略函数$\\pi_{\\theta}$学习一个映射从观测$o_t^{a}$到一个范围的分布或者是映射到一个高斯函数的动作均值和方差用于之后采样动作。</p>\n<ul>\n<li>Actor的优化目标为：</li>\n</ul>\n<p>$$L(\\theta) &#x3D; [\\frac{1}{B_n}\\sum_{i&#x3D;1}^{B}\\sum_{k-1}^{n}min(r_{\\theta,i}^{(k)}A_{i}^{(k)},clip(r_{\\theta,i}^{(k)},1-\\epsilon,1+\\epsilon)A_i^{(k)})]+\\sigma \\frac{1}{B_n}\\sum_{i&#x3D;1}^{B}\\sum_{k-1}^{n}S[\\pi_{\\theta}(o_i^{(k)})],where r_{\\theta,i}^{(k)}&#x3D;\\frac{\\pi_{\\theta}(a_i^{(k)}|o_i^{(k)})}{\\pi_{\\theta_{old}}(a_i^{(k)}|o_i^{(k)})}$$</p>\n<p>其中优势函数$A_i^{(k)}$是采用GAE方法的，S表示策略的熵，$\\sigma$是控制熵系数的一个超参数。</p>\n<ul>\n<li>Critic网络优化目标为：</li>\n</ul>\n<p>$$L(\\phi)&#x3D;\\frac{1}{B_n}\\sum_{i&#x3D;1}^{B}\\sum_{k&#x3D;1}^{n}(max[(V_\\phi(s_i^{(k)})-\\hat R_i)^2,(clip(V_\\phi(s_i^{(k)}),V_{\\phi_{old}}(s_i^{(k)}-\\varepsilon),V_{\\phi_{old}}(s_i^{(k)}+\\varepsilon)-\\hat R_i)^2]$$</p>\n<p>其中$\\hat R_i$是折扣奖励。B表示batch_size的大小，n表示智能体的数量。</p>\n<h3 id=\"代码整体流程\"><a href=\"#代码整体流程\" class=\"headerlink\" title=\"代码整体流程\"></a>代码整体流程</h3><p>每个局部智能体接收一个局部的观察obs，输出一个动作概率，所有的actor智能体都采用一个actor网络。critic网络接收所有智能体的观测obs，<code>cent_obs_space = n * obs_space</code>，其中n为智能体的个数，输出一个V值，V值用于actor的更新。actor的loss和PPO的loss类似，有添加一个熵的loss。Critic的loss更多的是对value的值做normalizer，并且在计算episode的折扣奖励的时候不是单纯的算折扣奖励，有采用gae算折扣回报的方式。</p>\n<ul>\n<li><p>网络定义</p>\n<p>代码定义在<code>onpolicy/algorithms/r_mappo/algorithm/rMAPPOPolicy.py</code></p>\n<p>每一个智能体的观测obs_space为一个18维的向量，有3个智能体，cent_obs_space为一个54维的向量，单个智能体的动作空间act_space 为一个离散的5维的向量</p>\n</li>\n</ul>\n<ol>\n<li><p>actor</p>\n<p>在<code>onpolicy/algorithms/utils/act.py</code>中，输入一个观测（18维），输出一个确切的动作actions和这个动作对数概率。</p>\n</li>\n</ol>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">action_dim <span class=\"token operator\">=</span> action_space<span class=\"token punctuation\">.</span>n\nself<span class=\"token punctuation\">.</span>action_out <span class=\"token operator\">=</span> Categorical<span class=\"token punctuation\">(</span>inputs_dim<span class=\"token punctuation\">,</span> action_dim<span class=\"token punctuation\">,</span> use_orthogonal<span class=\"token punctuation\">,</span> gain<span class=\"token punctuation\">)</span>\naction_logits <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>action_out<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> available_actions<span class=\"token punctuation\">)</span>\nactions <span class=\"token operator\">=</span> action_logits<span class=\"token punctuation\">.</span>mode<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">if</span> deterministic <span class=\"token keyword\">else</span> action_logits<span class=\"token punctuation\">.</span>sample<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> \naction_log_probs <span class=\"token operator\">=</span> action_logits<span class=\"token punctuation\">.</span>log_probs<span class=\"token punctuation\">(</span>actions<span class=\"token punctuation\">)</span></code></pre>\n\n<ol start=\"2\">\n<li><p>critic</p>\n<p>critic输入维度为<code>cent_obs_space = n * obs_space = 54</code>，输出维度为1。</p>\n</li>\n</ol>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">critic_features <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>base<span class=\"token punctuation\">(</span>cent_obs<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">if</span> self<span class=\"token punctuation\">.</span>_use_naive_recurrent_policy <span class=\"token keyword\">or</span> self<span class=\"token punctuation\">.</span>_use_recurrent_policy<span class=\"token punctuation\">:</span>\n        critic_features<span class=\"token punctuation\">,</span> rnn_states <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>rnn<span class=\"token punctuation\">(</span>critic_features<span class=\"token punctuation\">,</span> rnn_states<span class=\"token punctuation\">,</span> masks<span class=\"token punctuation\">)</span>\nvalues <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>v_out<span class=\"token punctuation\">(</span>critic_features<span class=\"token punctuation\">)</span></code></pre>\n\n<h3 id=\"采样流程\"><a href=\"#采样流程\" class=\"headerlink\" title=\"采样流程\"></a>采样流程</h3><ul>\n<li>初始化obs</li>\n</ul>\n<p>在on policy&#x2F;scripts&#x2F;train&#x2F;train_mpe.py的make_train_env(all_args)函数中实例化4个环境：</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">return</span> SubprocVecEnv<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>get_env_fn<span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>all_args<span class=\"token punctuation\">.</span>n_rollout_threads<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre>\n\n<p>在onpolicy&#x2F;runner&#x2F;shared&#x2F;mpe_runner.py中的的warmup函数中，如果采用centralized_V值函数的训练方式（？？？），那么需要初始化的时候构造出多个智能体的share_obs：</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">obs <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>envs<span class=\"token punctuation\">.</span>reset<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># shape = (4, 3, 18)</span>\nshare_obs <span class=\"token operator\">=</span> obs<span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>n_rollout_threads<span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># shape = (4, 54)</span>\n<span class=\"token comment\"># 指定3个智能体</span>\nshare_obs <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>expand_dims<span class=\"token punctuation\">(</span>share_obs<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>repeat<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>num_agents<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># shape = (4, 3, 54)</span></code></pre>\n\n<p>在share_obs中会将n&#x3D;3个智能体的obs叠加在一起作为share_obs。</p>\n<ul>\n<li><code>collect()</code>采用<code>rollout</code>方式采样数据</li>\n</ul>\n<p>在onpolicy&#x2F;runner&#x2F;shared&#x2F;mpe_runner.py中的的collect函数中，调用<code>self.trainer.prep_rollout()</code>函数将actor和critic都设置为<code>eval()</code>格式,然后用<code>np.concatenate()</code>函数将并行的环境的数据拼接在一起，这一步是将并行采样的那个纬度降掉:</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">value<span class=\"token punctuation\">,</span> action<span class=\"token punctuation\">,</span> action_log_prob<span class=\"token punctuation\">,</span> rnn_states<span class=\"token punctuation\">,</span> rnn_states_critic \\\n    <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>trainer<span class=\"token punctuation\">.</span>policy<span class=\"token punctuation\">.</span>get_actions<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>concatenate<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span><span class=\"token builtin\">buffer</span><span class=\"token punctuation\">.</span>share_obs<span class=\"token punctuation\">[</span>step<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                            np<span class=\"token punctuation\">.</span>concatenate<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span><span class=\"token builtin\">buffer</span><span class=\"token punctuation\">.</span>obs<span class=\"token punctuation\">[</span>step<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                            np<span class=\"token punctuation\">.</span>concatenate<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span><span class=\"token builtin\">buffer</span><span class=\"token punctuation\">.</span>rnn_states<span class=\"token punctuation\">[</span>step<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token comment\"># ?</span>\n                            np<span class=\"token punctuation\">.</span>concatenate<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span><span class=\"token builtin\">buffer</span><span class=\"token punctuation\">.</span>rnn_states_critic<span class=\"token punctuation\">[</span>step<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                            np<span class=\"token punctuation\">.</span>concatenate<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span><span class=\"token builtin\">buffer</span><span class=\"token punctuation\">.</span>masks<span class=\"token punctuation\">[</span>step<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre>\n\n<p>将数据传入总的MAPPO策略网络R_MAPPOPolicy(onpolicy&#x2F;algorithms&#x2F;r_mappo&#x2F;algorithm&#x2F;rMAPPOPolicy.py)中去获取一个时间步的数据。在get_actions()里面调用actor去获取动作以及动作的对数概率，critic网络去获取对于cent_obs的状态值函数的输出：</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token comment\"># 调用actor去获取动作和动作的对数概率                                      </span>\nactions<span class=\"token punctuation\">,</span> action_log_probs<span class=\"token punctuation\">,</span> rnn_states_actor <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>actor<span class=\"token punctuation\">(</span>obs<span class=\"token punctuation\">,</span>rnn_states_actor<span class=\"token punctuation\">,</span> masks<span class=\"token punctuation\">,</span> available_actions<span class=\"token punctuation\">,</span> deterministic<span class=\"token punctuation\">)</span></code></pre>\n\n<p>在这里obs的shape是(4*3, 18),输出actions和action_log_probs的shape都为(12,1).</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">values<span class=\"token punctuation\">,</span> rnn_states_critic <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>critic<span class=\"token punctuation\">(</span>cent_obs<span class=\"token punctuation\">,</span> rnn_states_critic<span class=\"token punctuation\">,</span> masks<span class=\"token punctuation\">)</span>   <span class=\"token comment\"># 调用critic去对动作打分，得到values</span></code></pre>\n\n<p>cent_obs’s shape is (5*2, 14),values’s shape is (12,1),and rnn_states’s shape is (12, 1, 64).</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">values <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span>_t2n<span class=\"token punctuation\">(</span>value<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>n_rollout_threads<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>   <span class=\"token comment\"># 将value转化成4层3行1列的数据</span>\n        actions <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span>_t2n<span class=\"token punctuation\">(</span>action<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>n_rollout_threads<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>   <span class=\"token comment\"># 这action转化成4层3行1列的数据</span>\n        action_log_probs <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span>_t2n<span class=\"token punctuation\">(</span>action_log_prob<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>n_rollout_threads<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        rnn_states <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span>_t2n<span class=\"token punctuation\">(</span>rnn_states<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>n_rollout_threads<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        rnn_states_critic <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span>_t2n<span class=\"token punctuation\">(</span>rnn_states_critic<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>n_rollout_threads<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\nactions_env <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>squeeze<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>eye<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>envs<span class=\"token punctuation\">.</span>action_space<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span>actions<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 5维 (4, 3, 5)</span></code></pre>\n\n<p>最后将(<code>12 , 1</code>)的<code>actions</code>转换成(<code>4, 3, 1</code>)的形式，方便之后并行送到并行的环境中去，作者这里还将动作进行了<code>one-hot</code>编码，最后变成了(<code>4, 3, 5</code>)的形式送入到环境中去。</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token comment\"># Obser reward and next obs</span>\nobs<span class=\"token punctuation\">,</span> rewards<span class=\"token punctuation\">,</span> dones<span class=\"token punctuation\">,</span> infos <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>envs<span class=\"token punctuation\">.</span>step<span class=\"token punctuation\">(</span>actions_env<span class=\"token punctuation\">)</span>\ndata <span class=\"token operator\">=</span> obs<span class=\"token punctuation\">,</span> rewards<span class=\"token punctuation\">,</span> dones<span class=\"token punctuation\">,</span> infos<span class=\"token punctuation\">,</span> values<span class=\"token punctuation\">,</span> actions<span class=\"token punctuation\">,</span> action_log_probs<span class=\"token punctuation\">,</span> rnn_states<span class=\"token punctuation\">,</span> rnn_states_critic\n<span class=\"token comment\"># insert data into buffer</span>\nself<span class=\"token punctuation\">.</span>insert<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span></code></pre>\n\n<p>环境下一次输出的<code>obs</code>还是(<code>4, 3, 18</code>)的形式，之后调<code>insert</code>方法将数据添加到<code>buffer</code>里面，在<code>insert</code>方法里面会将局部观测构造一个全局观测<code>share_obs</code>其shape&#x3D;(<code>4, 3, 54</code>)出来：</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">insert</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    obs<span class=\"token punctuation\">,</span> rewards<span class=\"token punctuation\">,</span> dones<span class=\"token punctuation\">,</span> infos<span class=\"token punctuation\">,</span> values<span class=\"token punctuation\">,</span> actions<span class=\"token punctuation\">,</span> action_log_probs<span class=\"token punctuation\">,</span> rnn_states<span class=\"token punctuation\">,</span> rnn_states_critic <span class=\"token operator\">=</span> data\n    rnn_states<span class=\"token punctuation\">[</span>dones <span class=\"token operator\">==</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>dones <span class=\"token operator\">==</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>recurrent_N<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>hidden_size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span>\n    rnn_states_critic<span class=\"token punctuation\">[</span>dones <span class=\"token operator\">==</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>dones <span class=\"token operator\">==</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">*</span>self<span class=\"token punctuation\">.</span><span class=\"token builtin\">buffer</span><span class=\"token punctuation\">.</span>rnn_states_critic<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span>\n    masks <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>ones<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>n_rollout_threads<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>num_agents<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span>\n    masks<span class=\"token punctuation\">[</span>dones <span class=\"token operator\">==</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>dones <span class=\"token operator\">==</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">if</span> self<span class=\"token punctuation\">.</span>use_centralized_V<span class=\"token punctuation\">:</span>\n        share_obs <span class=\"token operator\">=</span> obs<span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>n_rollout_threads<span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        share_obs <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>expand_dims<span class=\"token punctuation\">(</span>share_obs<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>repeat<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>num_agents<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n        share_obs <span class=\"token operator\">=</span> obs\n    self<span class=\"token punctuation\">.</span><span class=\"token builtin\">buffer</span><span class=\"token punctuation\">.</span>insert<span class=\"token punctuation\">(</span>share_obs<span class=\"token punctuation\">,</span> obs<span class=\"token punctuation\">,</span> rnn_states<span class=\"token punctuation\">,</span> rnn_states_critic<span class=\"token punctuation\">,</span> actions<span class=\"token punctuation\">,</span> action_log_probs<span class=\"token punctuation\">,</span> values<span class=\"token punctuation\">,</span> rewards<span class=\"token punctuation\">,</span> masks<span class=\"token punctuation\">)</span></code></pre>\n\n<p>上述过程循环迭代<code>self.episode_length=100</code>次。</p>\n<h3 id=\"训练流程\"><a href=\"#训练流程\" class=\"headerlink\" title=\"训练流程\"></a>训练流程</h3><ul>\n<li>计算优势函数</li>\n</ul>\n<p>在训练之前，首先调用<code>self.compute()</code>函数计算<code>episode</code>的折扣回报，在计算折扣回报之前，先算这个<code>episode</code>最后一个状态的状态值函数<code>next_values</code>，其<code>shape=(12, 1)</code>然后调用<code>compute_returns</code>函数计算折扣回报:</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">compute</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>  <span class=\"token comment\"># 计算这个episode的折扣回报，先用rMAPPOPolicy.py里面的get_values计算一下next_values</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"Calculate returns for the collected data.\"\"\"</span>\n    self<span class=\"token punctuation\">.</span>trainer<span class=\"token punctuation\">.</span>prep_rollout<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    next_values <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>trainer<span class=\"token punctuation\">.</span>policy<span class=\"token punctuation\">.</span>get_values<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>concatenate<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span><span class=\"token builtin\">buffer</span><span class=\"token punctuation\">.</span>share_obs<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                                             np<span class=\"token punctuation\">.</span>concatenate<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span><span class=\"token builtin\">buffer</span><span class=\"token punctuation\">.</span>rnn_states_critic<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                                             np<span class=\"token punctuation\">.</span>concatenate<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span><span class=\"token builtin\">buffer</span><span class=\"token punctuation\">.</span>masks<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    next_values <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span>_t2n<span class=\"token punctuation\">(</span>next_values<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>n_rollout_threads<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    self<span class=\"token punctuation\">.</span><span class=\"token builtin\">buffer</span><span class=\"token punctuation\">.</span>compute_returns<span class=\"token punctuation\">(</span>next_values<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>trainer<span class=\"token punctuation\">.</span>value_normalizer<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 折扣回报的的计算方式</span></code></pre>\n\n<p>有了数据之后就可以开始计算<strong>折扣回报</strong>了（在这里有采用<code>gae</code>算折扣回报的方式，并且有将<code>value</code>做<code>normalizer</code>）。<code>compute_returns</code>函数在<code>onpolicy/utils/shared_buffer.py</code> 中，核心代码如下：</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">self<span class=\"token punctuation\">.</span>value_preds<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> next_value\ngae <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n<span class=\"token keyword\">for</span> step <span class=\"token keyword\">in</span> <span class=\"token builtin\">reversed</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>rewards<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">if</span> self<span class=\"token punctuation\">.</span>_use_popart <span class=\"token keyword\">or</span> self<span class=\"token punctuation\">.</span>_use_valuenorm<span class=\"token punctuation\">:</span>\n    delta <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>rewards<span class=\"token punctuation\">[</span>step<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> self<span class=\"token punctuation\">.</span>gamma <span class=\"token operator\">*</span> value_normalizer<span class=\"token punctuation\">.</span>denormalize<span class=\"token punctuation\">(</span>\n      self<span class=\"token punctuation\">.</span>value_preds<span class=\"token punctuation\">[</span>step <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> self<span class=\"token punctuation\">.</span>masks<span class=\"token punctuation\">[</span>step <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span> \\ \n    <span class=\"token operator\">-</span> value_normalizer<span class=\"token punctuation\">.</span>denormalize<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>value_preds<span class=\"token punctuation\">[</span>step<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    gae <span class=\"token operator\">=</span> delta <span class=\"token operator\">+</span> self<span class=\"token punctuation\">.</span>gamma <span class=\"token operator\">*</span> self<span class=\"token punctuation\">.</span>gae_lambda <span class=\"token operator\">*</span> self<span class=\"token punctuation\">.</span>masks<span class=\"token punctuation\">[</span>step <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> gae\n    self<span class=\"token punctuation\">.</span>returns<span class=\"token punctuation\">[</span>step<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> gae <span class=\"token operator\">+</span> value_normalizer<span class=\"token punctuation\">.</span>denormalize<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>value_preds<span class=\"token punctuation\">[</span>step<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre>\n\n<p>算完折扣回报后调用<code>self.train()</code>函数进行训练:</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">train</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>  <span class=\"token comment\"># 算完折扣回报之后调用self.train()函数进行训练</span>\n  <span class=\"token triple-quoted-string string\">\"\"\"Train policies with data in buffer. \"\"\"</span>\n  self<span class=\"token punctuation\">.</span>trainer<span class=\"token punctuation\">.</span>prep_training<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 将网络设置为train（）的格式</span>\n  train_infos <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>trainer<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span><span class=\"token builtin\">buffer</span><span class=\"token punctuation\">)</span>      \n  self<span class=\"token punctuation\">.</span><span class=\"token builtin\">buffer</span><span class=\"token punctuation\">.</span>after_update<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 将buffer的第一个元素设置为其episode最后的一个元素</span>\n  <span class=\"token keyword\">return</span> train_infos</code></pre>\n\n<p>在<code>self.trainer.train(self.buffer)</code>函数中先基于数据，计算优势函数(优势函数是针对全局的观测信息所得到的)：</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">advantages <span class=\"token operator\">=</span> <span class=\"token builtin\">buffer</span><span class=\"token punctuation\">.</span>returns<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">-</span> self<span class=\"token punctuation\">.</span>value_normalizer<span class=\"token punctuation\">.</span>denormalize<span class=\"token punctuation\">(</span><span class=\"token builtin\">buffer</span><span class=\"token punctuation\">.</span>value_preds<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nadvantages_copy <span class=\"token operator\">=</span> advantages<span class=\"token punctuation\">.</span>copy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nadvantages_copy<span class=\"token punctuation\">[</span><span class=\"token builtin\">buffer</span><span class=\"token punctuation\">.</span>active_masks<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token number\">0.0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>nan\nmean_advantages <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>nanmean<span class=\"token punctuation\">(</span>advantages_copy<span class=\"token punctuation\">)</span> <span class=\"token comment\"># float, shape = (1)</span>\nstd_advantages <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>nanstd<span class=\"token punctuation\">(</span>advantages_copy<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># float, shape = (1)</span>\nadvantages <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>advantages <span class=\"token operator\">-</span> mean_advantages<span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> <span class=\"token punctuation\">(</span>std_advantages <span class=\"token operator\">+</span> <span class=\"token number\">1e-5</span><span class=\"token punctuation\">)</span></code></pre>\n\n<p>然后从<code>buffer</code>中采样数据，把线程、智能体的纬度全部降掉</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token comment\"># 从 data_generator 中采样</span>\n<span class=\"token keyword\">for</span> sample <span class=\"token keyword\">in</span> data_generator<span class=\"token punctuation\">:</span>\n  <span class=\"token comment\"># 进行一次 PPO 更新</span>\n  value_loss<span class=\"token punctuation\">,</span> critic_grad_norm<span class=\"token punctuation\">,</span> policy_loss<span class=\"token punctuation\">,</span> dist_entropy<span class=\"token punctuation\">,</span> actor_grad_norm<span class=\"token punctuation\">,</span> imp_weights \\\n                        <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>ppo_update<span class=\"token punctuation\">(</span>sample<span class=\"token punctuation\">,</span> update_actor<span class=\"token punctuation\">)</span></code></pre>\n\n<p><code>ppo_update</code>函数大体流程是:</p>\n<ol>\n<li>从buffer中抽样建立sample</li>\n<li>将抽样的数据传递给rMAPPOPolicy.py中的evaluate_actions函数，得到 values, action_log_probs, dist_entropy</li>\n<li>计算actor的loss</li>\n<li>计算critic的loss</li>\n</ol>\n<p>然后在<code>onpolicy/algorithms/r_mappo/r_mappo.py</code>中</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">share_obs_batch<span class=\"token punctuation\">,</span> obs_batch<span class=\"token punctuation\">,</span> rnn_states_batch<span class=\"token punctuation\">,</span> rnn_states_critic_batch<span class=\"token punctuation\">,</span> actions_batch<span class=\"token punctuation\">,</span>\\ \n        value_preds_batch<span class=\"token punctuation\">,</span> return_batch<span class=\"token punctuation\">,</span>masks_batch<span class=\"token punctuation\">,</span>active_masks_batch<span class=\"token punctuation\">,</span>old_action_log_probs_batch<span class=\"token punctuation\">,</span> \\\n        adv_targ<span class=\"token punctuation\">,</span> available_actions_batch <span class=\"token operator\">=</span> sample</code></pre>\n\n<p>拿到采样之后的数据，把<code>obs</code>送给<code>actor</code>网络，得到<code>action_log_probs</code>, <code>dist_entropy</code>。把<code>cent_obs</code>送到<code>critic</code>得到新的<code>values</code>。</p>\n<ul>\n<li>计算actor的loss</li>\n</ul>\n<p>在<code>ppo_update()</code>中，利用新老动作的概率分布和优势函数之后就可以更新<code>actor</code>网络了：</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token comment\"># actor update</span>\nimp_weights <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>exp<span class=\"token punctuation\">(</span>action_log_probs <span class=\"token operator\">-</span> old_action_log_probs_batch<span class=\"token punctuation\">)</span>\n\nsurr1 <span class=\"token operator\">=</span> imp_weights <span class=\"token operator\">*</span> adv_targ\nsurr2 <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>clamp<span class=\"token punctuation\">(</span>imp_weights<span class=\"token punctuation\">,</span> <span class=\"token number\">1.0</span> <span class=\"token operator\">-</span> self<span class=\"token punctuation\">.</span>clip_param<span class=\"token punctuation\">,</span> <span class=\"token number\">1.0</span> <span class=\"token operator\">+</span> self<span class=\"token punctuation\">.</span>clip_param<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> adv_targ\npolicy_action_loss <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">-</span>torch<span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span><span class=\"token builtin\">min</span><span class=\"token punctuation\">(</span>surr1<span class=\"token punctuation\">,</span> surr2<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                                             dim<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span>\n                                             keepdim<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> active_masks_batch<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> active_masks_batch<span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">(</span>policy_loss <span class=\"token operator\">-</span> dist_entropy <span class=\"token operator\">*</span> self<span class=\"token punctuation\">.</span>entropy_coef<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>backward<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre>\n\n<ul>\n<li>计算critic的loss</li>\n</ul>\n<p>新的<code>value</code>和老的<code>value_preds_batch</code>和计算的<code>return_batch</code>送到<code>onpolicy/algorithms/r_mappo/r_mappo.py</code>文件的<code>cal_value_loss</code>函数中去计算<code>critic</code>的<code>loss</code>：</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">value_loss <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>cal_value_loss<span class=\"token punctuation\">(</span>values<span class=\"token punctuation\">,</span> value_preds_batch<span class=\"token punctuation\">,</span> return_batch<span class=\"token punctuation\">,</span> active_masks_batch<span class=\"token punctuation\">)</span></code></pre>\n\n<p>and then</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token comment\"># 对value做一个clipped</span>\nvalue_pred_clipped <span class=\"token operator\">=</span> value_preds_batch <span class=\"token operator\">+</span> <span class=\"token punctuation\">(</span>values <span class=\"token operator\">-</span> value_preds_batch<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>clamp<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span>self<span class=\"token punctuation\">.</span>clip_param<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>clip_param<span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># 然后计算误差的clip</span>\nerror_clipped <span class=\"token operator\">=</span> return_batch <span class=\"token operator\">-</span> value_pred_clipped\nerror_original <span class=\"token operator\">=</span> return_batch <span class=\"token operator\">-</span> values\n<span class=\"token comment\"># 然后直接计算loss</span>\nvalue_loss_clipped <span class=\"token operator\">=</span> mse_loss<span class=\"token punctuation\">(</span>error_clipped<span class=\"token punctuation\">)</span>\nvalue_loss_original <span class=\"token operator\">=</span> mse_loss<span class=\"token punctuation\">(</span>error_original<span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># 算出loss之后反向传播即可</span>\n<span class=\"token punctuation\">(</span>value_loss <span class=\"token operator\">*</span> self<span class=\"token punctuation\">.</span>value_loss_coef<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>backward<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre>\n\n<h3 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h3><ol>\n<li>多智能体强化学习(二) MAPPO算法详解 <a href=\"https://blog.csdn.net/weixin_39059031/article/details/117283800\">https://blog.csdn.net/weixin_39059031/article/details/117283800</a></li>\n<li>多智能体强化学习MAPPO源代码解读 <a href=\"https://blog.csdn.net/onlyyyyyyee/article/details/118888711\">https://blog.csdn.net/onlyyyyyyee/article/details/118888711</a></li>\n</ol>\n","more":"<h2 id=\"代码运行\"><a href=\"#代码运行\" class=\"headerlink\" title=\"代码运行\"></a>代码运行</h2><p>使用conda新建环境，python版本推荐为3.6.7，并且安装readme中的MPE环境，然后将pycharm中train_mpe.py文件的configuration中的参数设置为<code>--env_name &quot;MPE&quot; --algorithm_name &quot;rmappo&quot; --experiment_name &quot;check&quot; --scenario_name &quot;simple_spread&quot; --num_agents 3 --num_landmarks 3 --seed 1 --n_training_threads 1 --n_rollout_threads 4 --num_mini_batch 1 --episode_length 25 --num_env_steps 10000 --ppo_epoch 10 --use_ReLU --gain 0.01 --lr 7e-4 --critic_lr 7e-4 --wandb_name &quot;leafii&quot; --user_name &quot;leafii&quot;</code>，以免因为电脑配置不足无法运行。安装其他包时要参考文件夹中requirement.txt中的版本，以免由于版本兼容问题造成代码无法正常运行，debug。</p>\n<h3 id=\"MAPPO算法伪代码\"><a href=\"#MAPPO算法伪代码\" class=\"headerlink\" title=\"MAPPO算法伪代码\"></a>MAPPO算法伪代码</h3><p><img src=\"http://cdn.leafii.top/img/mappo.png\" alt=\"img\"></p>\n<p>有两个网络，分别是策略$\\pi_{\\theta}$和值函数$V_{\\phi}$。（作者在文中说如果智能体是同种类的就采用相同的网络参数，对于每个智能体内部也可以采用各自的actor和critic网络，为了符号的便利性，作者直接使用一个网络参数来表示）。值函数$V_{\\phi}$需要学习一个映射： $S \\rightarrow \\mathbb R$。策略函数$\\pi_{\\theta}$学习一个映射从观测$o_t^{a}$到一个范围的分布或者是映射到一个高斯函数的动作均值和方差用于之后采样动作。</p>\n<ul>\n<li>Actor的优化目标为：</li>\n</ul>\n<p>$$L(\\theta) &#x3D; [\\frac{1}{B_n}\\sum_{i&#x3D;1}^{B}\\sum_{k-1}^{n}min(r_{\\theta,i}^{(k)}A_{i}^{(k)},clip(r_{\\theta,i}^{(k)},1-\\epsilon,1+\\epsilon)A_i^{(k)})]+\\sigma \\frac{1}{B_n}\\sum_{i&#x3D;1}^{B}\\sum_{k-1}^{n}S[\\pi_{\\theta}(o_i^{(k)})],where r_{\\theta,i}^{(k)}&#x3D;\\frac{\\pi_{\\theta}(a_i^{(k)}|o_i^{(k)})}{\\pi_{\\theta_{old}}(a_i^{(k)}|o_i^{(k)})}$$</p>\n<p>其中优势函数$A_i^{(k)}$是采用GAE方法的，S表示策略的熵，$\\sigma$是控制熵系数的一个超参数。</p>\n<ul>\n<li>Critic网络优化目标为：</li>\n</ul>\n<p>$$L(\\phi)&#x3D;\\frac{1}{B_n}\\sum_{i&#x3D;1}^{B}\\sum_{k&#x3D;1}^{n}(max[(V_\\phi(s_i^{(k)})-\\hat R_i)^2,(clip(V_\\phi(s_i^{(k)}),V_{\\phi_{old}}(s_i^{(k)}-\\varepsilon),V_{\\phi_{old}}(s_i^{(k)}+\\varepsilon)-\\hat R_i)^2]$$</p>\n<p>其中$\\hat R_i$是折扣奖励。B表示batch_size的大小，n表示智能体的数量。</p>\n<h3 id=\"代码整体流程\"><a href=\"#代码整体流程\" class=\"headerlink\" title=\"代码整体流程\"></a>代码整体流程</h3><p>每个局部智能体接收一个局部的观察obs，输出一个动作概率，所有的actor智能体都采用一个actor网络。critic网络接收所有智能体的观测obs，<code>cent_obs_space = n * obs_space</code>，其中n为智能体的个数，输出一个V值，V值用于actor的更新。actor的loss和PPO的loss类似，有添加一个熵的loss。Critic的loss更多的是对value的值做normalizer，并且在计算episode的折扣奖励的时候不是单纯的算折扣奖励，有采用gae算折扣回报的方式。</p>\n<ul>\n<li><p>网络定义</p>\n<p>代码定义在<code>onpolicy/algorithms/r_mappo/algorithm/rMAPPOPolicy.py</code></p>\n<p>每一个智能体的观测obs_space为一个18维的向量，有3个智能体，cent_obs_space为一个54维的向量，单个智能体的动作空间act_space 为一个离散的5维的向量</p>\n</li>\n</ul>\n<ol>\n<li><p>actor</p>\n<p>在<code>onpolicy/algorithms/utils/act.py</code>中，输入一个观测（18维），输出一个确切的动作actions和这个动作对数概率。</p>\n</li>\n</ol>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">action_dim <span class=\"token operator\">=</span> action_space<span class=\"token punctuation\">.</span>n\nself<span class=\"token punctuation\">.</span>action_out <span class=\"token operator\">=</span> Categorical<span class=\"token punctuation\">(</span>inputs_dim<span class=\"token punctuation\">,</span> action_dim<span class=\"token punctuation\">,</span> use_orthogonal<span class=\"token punctuation\">,</span> gain<span class=\"token punctuation\">)</span>\naction_logits <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>action_out<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> available_actions<span class=\"token punctuation\">)</span>\nactions <span class=\"token operator\">=</span> action_logits<span class=\"token punctuation\">.</span>mode<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">if</span> deterministic <span class=\"token keyword\">else</span> action_logits<span class=\"token punctuation\">.</span>sample<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> \naction_log_probs <span class=\"token operator\">=</span> action_logits<span class=\"token punctuation\">.</span>log_probs<span class=\"token punctuation\">(</span>actions<span class=\"token punctuation\">)</span></code></pre>\n\n<ol start=\"2\">\n<li><p>critic</p>\n<p>critic输入维度为<code>cent_obs_space = n * obs_space = 54</code>，输出维度为1。</p>\n</li>\n</ol>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">critic_features <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>base<span class=\"token punctuation\">(</span>cent_obs<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">if</span> self<span class=\"token punctuation\">.</span>_use_naive_recurrent_policy <span class=\"token keyword\">or</span> self<span class=\"token punctuation\">.</span>_use_recurrent_policy<span class=\"token punctuation\">:</span>\n        critic_features<span class=\"token punctuation\">,</span> rnn_states <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>rnn<span class=\"token punctuation\">(</span>critic_features<span class=\"token punctuation\">,</span> rnn_states<span class=\"token punctuation\">,</span> masks<span class=\"token punctuation\">)</span>\nvalues <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>v_out<span class=\"token punctuation\">(</span>critic_features<span class=\"token punctuation\">)</span></code></pre>\n\n<h3 id=\"采样流程\"><a href=\"#采样流程\" class=\"headerlink\" title=\"采样流程\"></a>采样流程</h3><ul>\n<li>初始化obs</li>\n</ul>\n<p>在on policy&#x2F;scripts&#x2F;train&#x2F;train_mpe.py的make_train_env(all_args)函数中实例化4个环境：</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">return</span> SubprocVecEnv<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>get_env_fn<span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>all_args<span class=\"token punctuation\">.</span>n_rollout_threads<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre>\n\n<p>在onpolicy&#x2F;runner&#x2F;shared&#x2F;mpe_runner.py中的的warmup函数中，如果采用centralized_V值函数的训练方式（？？？），那么需要初始化的时候构造出多个智能体的share_obs：</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">obs <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>envs<span class=\"token punctuation\">.</span>reset<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># shape = (4, 3, 18)</span>\nshare_obs <span class=\"token operator\">=</span> obs<span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>n_rollout_threads<span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># shape = (4, 54)</span>\n<span class=\"token comment\"># 指定3个智能体</span>\nshare_obs <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>expand_dims<span class=\"token punctuation\">(</span>share_obs<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>repeat<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>num_agents<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># shape = (4, 3, 54)</span></code></pre>\n\n<p>在share_obs中会将n&#x3D;3个智能体的obs叠加在一起作为share_obs。</p>\n<ul>\n<li><code>collect()</code>采用<code>rollout</code>方式采样数据</li>\n</ul>\n<p>在onpolicy&#x2F;runner&#x2F;shared&#x2F;mpe_runner.py中的的collect函数中，调用<code>self.trainer.prep_rollout()</code>函数将actor和critic都设置为<code>eval()</code>格式,然后用<code>np.concatenate()</code>函数将并行的环境的数据拼接在一起，这一步是将并行采样的那个纬度降掉:</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">value<span class=\"token punctuation\">,</span> action<span class=\"token punctuation\">,</span> action_log_prob<span class=\"token punctuation\">,</span> rnn_states<span class=\"token punctuation\">,</span> rnn_states_critic \\\n    <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>trainer<span class=\"token punctuation\">.</span>policy<span class=\"token punctuation\">.</span>get_actions<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>concatenate<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span><span class=\"token builtin\">buffer</span><span class=\"token punctuation\">.</span>share_obs<span class=\"token punctuation\">[</span>step<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                            np<span class=\"token punctuation\">.</span>concatenate<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span><span class=\"token builtin\">buffer</span><span class=\"token punctuation\">.</span>obs<span class=\"token punctuation\">[</span>step<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                            np<span class=\"token punctuation\">.</span>concatenate<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span><span class=\"token builtin\">buffer</span><span class=\"token punctuation\">.</span>rnn_states<span class=\"token punctuation\">[</span>step<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token comment\"># ?</span>\n                            np<span class=\"token punctuation\">.</span>concatenate<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span><span class=\"token builtin\">buffer</span><span class=\"token punctuation\">.</span>rnn_states_critic<span class=\"token punctuation\">[</span>step<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                            np<span class=\"token punctuation\">.</span>concatenate<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span><span class=\"token builtin\">buffer</span><span class=\"token punctuation\">.</span>masks<span class=\"token punctuation\">[</span>step<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre>\n\n<p>将数据传入总的MAPPO策略网络R_MAPPOPolicy(onpolicy&#x2F;algorithms&#x2F;r_mappo&#x2F;algorithm&#x2F;rMAPPOPolicy.py)中去获取一个时间步的数据。在get_actions()里面调用actor去获取动作以及动作的对数概率，critic网络去获取对于cent_obs的状态值函数的输出：</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token comment\"># 调用actor去获取动作和动作的对数概率                                      </span>\nactions<span class=\"token punctuation\">,</span> action_log_probs<span class=\"token punctuation\">,</span> rnn_states_actor <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>actor<span class=\"token punctuation\">(</span>obs<span class=\"token punctuation\">,</span>rnn_states_actor<span class=\"token punctuation\">,</span> masks<span class=\"token punctuation\">,</span> available_actions<span class=\"token punctuation\">,</span> deterministic<span class=\"token punctuation\">)</span></code></pre>\n\n<p>在这里obs的shape是(4*3, 18),输出actions和action_log_probs的shape都为(12,1).</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">values<span class=\"token punctuation\">,</span> rnn_states_critic <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>critic<span class=\"token punctuation\">(</span>cent_obs<span class=\"token punctuation\">,</span> rnn_states_critic<span class=\"token punctuation\">,</span> masks<span class=\"token punctuation\">)</span>   <span class=\"token comment\"># 调用critic去对动作打分，得到values</span></code></pre>\n\n<p>cent_obs’s shape is (5*2, 14),values’s shape is (12,1),and rnn_states’s shape is (12, 1, 64).</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">values <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span>_t2n<span class=\"token punctuation\">(</span>value<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>n_rollout_threads<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>   <span class=\"token comment\"># 将value转化成4层3行1列的数据</span>\n        actions <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span>_t2n<span class=\"token punctuation\">(</span>action<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>n_rollout_threads<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>   <span class=\"token comment\"># 这action转化成4层3行1列的数据</span>\n        action_log_probs <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span>_t2n<span class=\"token punctuation\">(</span>action_log_prob<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>n_rollout_threads<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        rnn_states <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span>_t2n<span class=\"token punctuation\">(</span>rnn_states<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>n_rollout_threads<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        rnn_states_critic <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span>_t2n<span class=\"token punctuation\">(</span>rnn_states_critic<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>n_rollout_threads<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\nactions_env <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>squeeze<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>eye<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>envs<span class=\"token punctuation\">.</span>action_space<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span>actions<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 5维 (4, 3, 5)</span></code></pre>\n\n<p>最后将(<code>12 , 1</code>)的<code>actions</code>转换成(<code>4, 3, 1</code>)的形式，方便之后并行送到并行的环境中去，作者这里还将动作进行了<code>one-hot</code>编码，最后变成了(<code>4, 3, 5</code>)的形式送入到环境中去。</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token comment\"># Obser reward and next obs</span>\nobs<span class=\"token punctuation\">,</span> rewards<span class=\"token punctuation\">,</span> dones<span class=\"token punctuation\">,</span> infos <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>envs<span class=\"token punctuation\">.</span>step<span class=\"token punctuation\">(</span>actions_env<span class=\"token punctuation\">)</span>\ndata <span class=\"token operator\">=</span> obs<span class=\"token punctuation\">,</span> rewards<span class=\"token punctuation\">,</span> dones<span class=\"token punctuation\">,</span> infos<span class=\"token punctuation\">,</span> values<span class=\"token punctuation\">,</span> actions<span class=\"token punctuation\">,</span> action_log_probs<span class=\"token punctuation\">,</span> rnn_states<span class=\"token punctuation\">,</span> rnn_states_critic\n<span class=\"token comment\"># insert data into buffer</span>\nself<span class=\"token punctuation\">.</span>insert<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span></code></pre>\n\n<p>环境下一次输出的<code>obs</code>还是(<code>4, 3, 18</code>)的形式，之后调<code>insert</code>方法将数据添加到<code>buffer</code>里面，在<code>insert</code>方法里面会将局部观测构造一个全局观测<code>share_obs</code>其shape&#x3D;(<code>4, 3, 54</code>)出来：</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">insert</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    obs<span class=\"token punctuation\">,</span> rewards<span class=\"token punctuation\">,</span> dones<span class=\"token punctuation\">,</span> infos<span class=\"token punctuation\">,</span> values<span class=\"token punctuation\">,</span> actions<span class=\"token punctuation\">,</span> action_log_probs<span class=\"token punctuation\">,</span> rnn_states<span class=\"token punctuation\">,</span> rnn_states_critic <span class=\"token operator\">=</span> data\n    rnn_states<span class=\"token punctuation\">[</span>dones <span class=\"token operator\">==</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>dones <span class=\"token operator\">==</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>recurrent_N<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>hidden_size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span>\n    rnn_states_critic<span class=\"token punctuation\">[</span>dones <span class=\"token operator\">==</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>dones <span class=\"token operator\">==</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">*</span>self<span class=\"token punctuation\">.</span><span class=\"token builtin\">buffer</span><span class=\"token punctuation\">.</span>rnn_states_critic<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span>\n    masks <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>ones<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>n_rollout_threads<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>num_agents<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span>\n    masks<span class=\"token punctuation\">[</span>dones <span class=\"token operator\">==</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>dones <span class=\"token operator\">==</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">if</span> self<span class=\"token punctuation\">.</span>use_centralized_V<span class=\"token punctuation\">:</span>\n        share_obs <span class=\"token operator\">=</span> obs<span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>n_rollout_threads<span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        share_obs <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>expand_dims<span class=\"token punctuation\">(</span>share_obs<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>repeat<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>num_agents<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n        share_obs <span class=\"token operator\">=</span> obs\n    self<span class=\"token punctuation\">.</span><span class=\"token builtin\">buffer</span><span class=\"token punctuation\">.</span>insert<span class=\"token punctuation\">(</span>share_obs<span class=\"token punctuation\">,</span> obs<span class=\"token punctuation\">,</span> rnn_states<span class=\"token punctuation\">,</span> rnn_states_critic<span class=\"token punctuation\">,</span> actions<span class=\"token punctuation\">,</span> action_log_probs<span class=\"token punctuation\">,</span> values<span class=\"token punctuation\">,</span> rewards<span class=\"token punctuation\">,</span> masks<span class=\"token punctuation\">)</span></code></pre>\n\n<p>上述过程循环迭代<code>self.episode_length=100</code>次。</p>\n<h3 id=\"训练流程\"><a href=\"#训练流程\" class=\"headerlink\" title=\"训练流程\"></a>训练流程</h3><ul>\n<li>计算优势函数</li>\n</ul>\n<p>在训练之前，首先调用<code>self.compute()</code>函数计算<code>episode</code>的折扣回报，在计算折扣回报之前，先算这个<code>episode</code>最后一个状态的状态值函数<code>next_values</code>，其<code>shape=(12, 1)</code>然后调用<code>compute_returns</code>函数计算折扣回报:</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">compute</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>  <span class=\"token comment\"># 计算这个episode的折扣回报，先用rMAPPOPolicy.py里面的get_values计算一下next_values</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"Calculate returns for the collected data.\"\"\"</span>\n    self<span class=\"token punctuation\">.</span>trainer<span class=\"token punctuation\">.</span>prep_rollout<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    next_values <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>trainer<span class=\"token punctuation\">.</span>policy<span class=\"token punctuation\">.</span>get_values<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>concatenate<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span><span class=\"token builtin\">buffer</span><span class=\"token punctuation\">.</span>share_obs<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                                             np<span class=\"token punctuation\">.</span>concatenate<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span><span class=\"token builtin\">buffer</span><span class=\"token punctuation\">.</span>rnn_states_critic<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                                             np<span class=\"token punctuation\">.</span>concatenate<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span><span class=\"token builtin\">buffer</span><span class=\"token punctuation\">.</span>masks<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    next_values <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span>_t2n<span class=\"token punctuation\">(</span>next_values<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>n_rollout_threads<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    self<span class=\"token punctuation\">.</span><span class=\"token builtin\">buffer</span><span class=\"token punctuation\">.</span>compute_returns<span class=\"token punctuation\">(</span>next_values<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>trainer<span class=\"token punctuation\">.</span>value_normalizer<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 折扣回报的的计算方式</span></code></pre>\n\n<p>有了数据之后就可以开始计算<strong>折扣回报</strong>了（在这里有采用<code>gae</code>算折扣回报的方式，并且有将<code>value</code>做<code>normalizer</code>）。<code>compute_returns</code>函数在<code>onpolicy/utils/shared_buffer.py</code> 中，核心代码如下：</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">self<span class=\"token punctuation\">.</span>value_preds<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> next_value\ngae <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n<span class=\"token keyword\">for</span> step <span class=\"token keyword\">in</span> <span class=\"token builtin\">reversed</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>rewards<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">if</span> self<span class=\"token punctuation\">.</span>_use_popart <span class=\"token keyword\">or</span> self<span class=\"token punctuation\">.</span>_use_valuenorm<span class=\"token punctuation\">:</span>\n    delta <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>rewards<span class=\"token punctuation\">[</span>step<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> self<span class=\"token punctuation\">.</span>gamma <span class=\"token operator\">*</span> value_normalizer<span class=\"token punctuation\">.</span>denormalize<span class=\"token punctuation\">(</span>\n      self<span class=\"token punctuation\">.</span>value_preds<span class=\"token punctuation\">[</span>step <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> self<span class=\"token punctuation\">.</span>masks<span class=\"token punctuation\">[</span>step <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span> \\ \n    <span class=\"token operator\">-</span> value_normalizer<span class=\"token punctuation\">.</span>denormalize<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>value_preds<span class=\"token punctuation\">[</span>step<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    gae <span class=\"token operator\">=</span> delta <span class=\"token operator\">+</span> self<span class=\"token punctuation\">.</span>gamma <span class=\"token operator\">*</span> self<span class=\"token punctuation\">.</span>gae_lambda <span class=\"token operator\">*</span> self<span class=\"token punctuation\">.</span>masks<span class=\"token punctuation\">[</span>step <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> gae\n    self<span class=\"token punctuation\">.</span>returns<span class=\"token punctuation\">[</span>step<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> gae <span class=\"token operator\">+</span> value_normalizer<span class=\"token punctuation\">.</span>denormalize<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>value_preds<span class=\"token punctuation\">[</span>step<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre>\n\n<p>算完折扣回报后调用<code>self.train()</code>函数进行训练:</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">train</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>  <span class=\"token comment\"># 算完折扣回报之后调用self.train()函数进行训练</span>\n  <span class=\"token triple-quoted-string string\">\"\"\"Train policies with data in buffer. \"\"\"</span>\n  self<span class=\"token punctuation\">.</span>trainer<span class=\"token punctuation\">.</span>prep_training<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 将网络设置为train（）的格式</span>\n  train_infos <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>trainer<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span><span class=\"token builtin\">buffer</span><span class=\"token punctuation\">)</span>      \n  self<span class=\"token punctuation\">.</span><span class=\"token builtin\">buffer</span><span class=\"token punctuation\">.</span>after_update<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 将buffer的第一个元素设置为其episode最后的一个元素</span>\n  <span class=\"token keyword\">return</span> train_infos</code></pre>\n\n<p>在<code>self.trainer.train(self.buffer)</code>函数中先基于数据，计算优势函数(优势函数是针对全局的观测信息所得到的)：</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">advantages <span class=\"token operator\">=</span> <span class=\"token builtin\">buffer</span><span class=\"token punctuation\">.</span>returns<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">-</span> self<span class=\"token punctuation\">.</span>value_normalizer<span class=\"token punctuation\">.</span>denormalize<span class=\"token punctuation\">(</span><span class=\"token builtin\">buffer</span><span class=\"token punctuation\">.</span>value_preds<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nadvantages_copy <span class=\"token operator\">=</span> advantages<span class=\"token punctuation\">.</span>copy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nadvantages_copy<span class=\"token punctuation\">[</span><span class=\"token builtin\">buffer</span><span class=\"token punctuation\">.</span>active_masks<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token number\">0.0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>nan\nmean_advantages <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>nanmean<span class=\"token punctuation\">(</span>advantages_copy<span class=\"token punctuation\">)</span> <span class=\"token comment\"># float, shape = (1)</span>\nstd_advantages <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>nanstd<span class=\"token punctuation\">(</span>advantages_copy<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># float, shape = (1)</span>\nadvantages <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>advantages <span class=\"token operator\">-</span> mean_advantages<span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> <span class=\"token punctuation\">(</span>std_advantages <span class=\"token operator\">+</span> <span class=\"token number\">1e-5</span><span class=\"token punctuation\">)</span></code></pre>\n\n<p>然后从<code>buffer</code>中采样数据，把线程、智能体的纬度全部降掉</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token comment\"># 从 data_generator 中采样</span>\n<span class=\"token keyword\">for</span> sample <span class=\"token keyword\">in</span> data_generator<span class=\"token punctuation\">:</span>\n  <span class=\"token comment\"># 进行一次 PPO 更新</span>\n  value_loss<span class=\"token punctuation\">,</span> critic_grad_norm<span class=\"token punctuation\">,</span> policy_loss<span class=\"token punctuation\">,</span> dist_entropy<span class=\"token punctuation\">,</span> actor_grad_norm<span class=\"token punctuation\">,</span> imp_weights \\\n                        <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>ppo_update<span class=\"token punctuation\">(</span>sample<span class=\"token punctuation\">,</span> update_actor<span class=\"token punctuation\">)</span></code></pre>\n\n<p><code>ppo_update</code>函数大体流程是:</p>\n<ol>\n<li>从buffer中抽样建立sample</li>\n<li>将抽样的数据传递给rMAPPOPolicy.py中的evaluate_actions函数，得到 values, action_log_probs, dist_entropy</li>\n<li>计算actor的loss</li>\n<li>计算critic的loss</li>\n</ol>\n<p>然后在<code>onpolicy/algorithms/r_mappo/r_mappo.py</code>中</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">share_obs_batch<span class=\"token punctuation\">,</span> obs_batch<span class=\"token punctuation\">,</span> rnn_states_batch<span class=\"token punctuation\">,</span> rnn_states_critic_batch<span class=\"token punctuation\">,</span> actions_batch<span class=\"token punctuation\">,</span>\\ \n        value_preds_batch<span class=\"token punctuation\">,</span> return_batch<span class=\"token punctuation\">,</span>masks_batch<span class=\"token punctuation\">,</span>active_masks_batch<span class=\"token punctuation\">,</span>old_action_log_probs_batch<span class=\"token punctuation\">,</span> \\\n        adv_targ<span class=\"token punctuation\">,</span> available_actions_batch <span class=\"token operator\">=</span> sample</code></pre>\n\n<p>拿到采样之后的数据，把<code>obs</code>送给<code>actor</code>网络，得到<code>action_log_probs</code>, <code>dist_entropy</code>。把<code>cent_obs</code>送到<code>critic</code>得到新的<code>values</code>。</p>\n<ul>\n<li>计算actor的loss</li>\n</ul>\n<p>在<code>ppo_update()</code>中，利用新老动作的概率分布和优势函数之后就可以更新<code>actor</code>网络了：</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token comment\"># actor update</span>\nimp_weights <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>exp<span class=\"token punctuation\">(</span>action_log_probs <span class=\"token operator\">-</span> old_action_log_probs_batch<span class=\"token punctuation\">)</span>\n\nsurr1 <span class=\"token operator\">=</span> imp_weights <span class=\"token operator\">*</span> adv_targ\nsurr2 <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>clamp<span class=\"token punctuation\">(</span>imp_weights<span class=\"token punctuation\">,</span> <span class=\"token number\">1.0</span> <span class=\"token operator\">-</span> self<span class=\"token punctuation\">.</span>clip_param<span class=\"token punctuation\">,</span> <span class=\"token number\">1.0</span> <span class=\"token operator\">+</span> self<span class=\"token punctuation\">.</span>clip_param<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> adv_targ\npolicy_action_loss <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">-</span>torch<span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span><span class=\"token builtin\">min</span><span class=\"token punctuation\">(</span>surr1<span class=\"token punctuation\">,</span> surr2<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                                             dim<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span>\n                                             keepdim<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> active_masks_batch<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> active_masks_batch<span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">(</span>policy_loss <span class=\"token operator\">-</span> dist_entropy <span class=\"token operator\">*</span> self<span class=\"token punctuation\">.</span>entropy_coef<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>backward<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre>\n\n<ul>\n<li>计算critic的loss</li>\n</ul>\n<p>新的<code>value</code>和老的<code>value_preds_batch</code>和计算的<code>return_batch</code>送到<code>onpolicy/algorithms/r_mappo/r_mappo.py</code>文件的<code>cal_value_loss</code>函数中去计算<code>critic</code>的<code>loss</code>：</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">value_loss <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>cal_value_loss<span class=\"token punctuation\">(</span>values<span class=\"token punctuation\">,</span> value_preds_batch<span class=\"token punctuation\">,</span> return_batch<span class=\"token punctuation\">,</span> active_masks_batch<span class=\"token punctuation\">)</span></code></pre>\n\n<p>and then</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token comment\"># 对value做一个clipped</span>\nvalue_pred_clipped <span class=\"token operator\">=</span> value_preds_batch <span class=\"token operator\">+</span> <span class=\"token punctuation\">(</span>values <span class=\"token operator\">-</span> value_preds_batch<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>clamp<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span>self<span class=\"token punctuation\">.</span>clip_param<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>clip_param<span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># 然后计算误差的clip</span>\nerror_clipped <span class=\"token operator\">=</span> return_batch <span class=\"token operator\">-</span> value_pred_clipped\nerror_original <span class=\"token operator\">=</span> return_batch <span class=\"token operator\">-</span> values\n<span class=\"token comment\"># 然后直接计算loss</span>\nvalue_loss_clipped <span class=\"token operator\">=</span> mse_loss<span class=\"token punctuation\">(</span>error_clipped<span class=\"token punctuation\">)</span>\nvalue_loss_original <span class=\"token operator\">=</span> mse_loss<span class=\"token punctuation\">(</span>error_original<span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># 算出loss之后反向传播即可</span>\n<span class=\"token punctuation\">(</span>value_loss <span class=\"token operator\">*</span> self<span class=\"token punctuation\">.</span>value_loss_coef<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>backward<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre>\n\n<h3 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h3><ol>\n<li>多智能体强化学习(二) MAPPO算法详解 <a href=\"https://blog.csdn.net/weixin_39059031/article/details/117283800\">https://blog.csdn.net/weixin_39059031/article/details/117283800</a></li>\n<li>多智能体强化学习MAPPO源代码解读 <a href=\"https://blog.csdn.net/onlyyyyyyee/article/details/118888711\">https://blog.csdn.net/onlyyyyyyee/article/details/118888711</a></li>\n</ol>","categories":[],"tags":[{"name":"python","path":"api/tags/python.json"},{"name":"强化学习","path":"api/tags/强化学习.json"}]}