{"title":"Pandas数据处理","slug":"Pandas数据处理","date":"2022-06-08T14:14:08.000Z","updated":"2022-06-12T15:17:57.530Z","comments":true,"path":"api/articles/Pandas数据处理.json","excerpt":"Pandas数据处理​\t\t本文主要写Pandas在数据处理时需要掌握的方法。","covers":null,"content":"<h1 id=\"Pandas数据处理\"><a href=\"#Pandas数据处理\" class=\"headerlink\" title=\"Pandas数据处理\"></a>Pandas数据处理</h1><p>​\t\t本文主要写Pandas在数据处理时需要掌握的方法。</p>\n<span id=\"more\"></span>\n\n<h2 id=\"运算方法\"><a href=\"#运算方法\" class=\"headerlink\" title=\"运算方法\"></a>运算方法</h2><p>​\t\t我们已经提过如何用Pandas有效地筛选数据，也知道一些基本的统计学运算方法，而在这一节中，我们想要关注的是在Pandas中如何运算。</p>\n<h3 id=\"筛选赋值运算\"><a href=\"#筛选赋值运算\" class=\"headerlink\" title=\"筛选赋值运算\"></a>筛选赋值运算</h3><p>​\t\t在之前筛选数据的教学中，我们能成功找出数据中的某个部分，那么针对这个找出的部分，我们对它进行操作也是没问题的。比如下面我们先生成一组数据，然后再对这组数据进行筛选运算。</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\ndata <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">12</span><span class=\"token punctuation\">,</span> <span class=\"token number\">12</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">6</span><span class=\"token punctuation\">,</span><span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ndf <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>\n  data<span class=\"token punctuation\">,</span>\n  index<span class=\"token operator\">=</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"abcdef\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n  columns<span class=\"token operator\">=</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"ABCD\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ndf</code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">    A   B   C   D\na -12 -11 -10  -9\nb  -8  -7  -6  -5\nc  -4  -3  -2  -1\nd   0   1   2   3\ne   4   5   6   7\nf   8   9  10  11</code></pre>\n\n<p>​\t\t筛选出<code>A</code>的column出来，对<code>A</code>的内容进行乘0的运算。</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">df<span class=\"token punctuation\">[</span><span class=\"token string\">\"A\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*=</span> <span class=\"token number\">0</span>\ndf</code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">   A   B   C   D\na  0 -11 -10  -9\nb  0  -7  -6  -5\nc  0  -3  -2  -1\nd  0   1   2   3\ne  0   5   6   7\nf  0   9  10  11</code></pre>\n\n<p>​\t\t同样，在筛选数据教学中我们提到的<code>iloc</code>,<code>loc</code>功能也是可以用来对某数据进行运算的。<code>iloc</code>找的是index，<code>loc</code>找的是标签。</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">df<span class=\"token punctuation\">.</span>loc<span class=\"token punctuation\">[</span><span class=\"token string\">\"a\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"A\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">100</span>\ndf<span class=\"token punctuation\">.</span>iloc<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">200</span>\ndf</code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">     A   B   C   D\na  100 -11 -10  -9\nb  200  -7  -6  -5\nc    0  -3  -2  -1\nd    0   1   2   3\ne    0   5   6   7\nf    0   9  10  11</code></pre>\n\n<p>​\t\t这只是赋值，现在你拿这些赋值的方法进行运算试试：</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">df<span class=\"token punctuation\">.</span>loc<span class=\"token punctuation\">[</span><span class=\"token string\">\"a\"</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> df<span class=\"token punctuation\">.</span>loc<span class=\"token punctuation\">[</span><span class=\"token string\">\"a\"</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> <span class=\"token number\">2</span>\ndf</code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">     A   B   C   D\na  200 -22 -20 -18\nb  200  -7  -6  -5\nc    0  -3  -2  -1\nd    0   1   2   3\ne    0   5   6   7\nf    0   9  10  11</code></pre>\n\n<p>​\t\t试一试条件运算，下面做的就是对于<code>df[&quot;A&quot;]</code>，我要找出<code>df[&quot;A&quot;]</code>中等于0的数，把这些数赋值成-1.</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">df<span class=\"token punctuation\">[</span><span class=\"token string\">\"A\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>df<span class=\"token punctuation\">[</span><span class=\"token string\">\"A\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span>\ndf</code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">     A   B   C   D\na  200 -22 -20 -18\nb  200  -7  -6  -5\nc   -1  -3  -2  -1\nd   -1   1   2   3\ne   -1   5   6   7\nf   -1   9  10  11</code></pre>\n\n<p>​\t\t基本上，pandas 中可以用于筛选数据的方法都可以用来进一步把筛选出来的数据赋予新的值。</p>\n<h3 id=\"Apply方法\"><a href=\"#Apply方法\" class=\"headerlink\" title=\"Apply方法\"></a>Apply方法</h3><p>​\t\t另一种比较方便的批处理数据的方法，我比较喜欢用的是 <code>apply</code>。这是一种可以针对数据做自定义功能的运算。意味着可以简化数据做复杂的功能运算。 上面我们提到的筛选运算，其实是一种简单的运算方式，如果当运算变得复杂，甚至还需要很多局部变量来缓存运算结果，我们就可以尝试把运算过程放置在一个 <code>func</code> 中， 模块化。</p>\n<p>​\t\t比如我定义下面这批数据：</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">9</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> columns<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'A'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'B'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\ndf</code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">   A  B\n0  4  9\n1  4  9\n2  4  9</code></pre>\n\n<p>​\t\t如果对<code>df</code>做全量的平方根计算，一般的方法是这样：</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">np<span class=\"token punctuation\">.</span>sqrt<span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t但是如果用<code>apply</code>，就会变成</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">df<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>sqrt<span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">     A    B\n0  2.0  3.0\n1  2.0  3.0\n2  2.0  3.0</code></pre>\n\n<p>​\t\t我们把<code>np.sqrt</code>这个函数当成一个参数传入了<code>apply</code>，看起来好像没什么用，还不如直接使用<code>np.sqrt(df)</code>来的方便。的确这个case写成<code>np.sqrt(df)</code>是要简单点。但是下面这种case呢？</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">func</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> x<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span>\n\ndf<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span>func<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> result_type<span class=\"token operator\">=</span><span class=\"token string\">'expand'</span><span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">   0  1\n0  8 -9\n1  8 -9\n2  8 -9</code></pre>\n\n<p>​\t\t在这个自定义的函数中，对 <code>df</code> 中的每一行，每行第 0 位乘以 2，第 1 位乘以 -1，我们原本的 col0，就都乘了 2，而 col1 就都乘了-1。提示一下，<code>apply</code> 里面还有不同的参数项可以选，我使用了一个 <code>result_type=&quot;expand&quot;</code> 的配置，让输出的结果可以生成多 column，要不然， 会只生成一个 column，所有的结果都写在这一个 column 里。要不你试试删除刚才写的 <code>result_type</code>，观察一下生成结果的变化。</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token comment\">#df.apply(func, axis=1)</span>\n<span class=\"token number\">0</span>    <span class=\"token punctuation\">(</span><span class=\"token number\">8</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">9</span><span class=\"token punctuation\">)</span>\n<span class=\"token number\">1</span>    <span class=\"token punctuation\">(</span><span class=\"token number\">8</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">9</span><span class=\"token punctuation\">)</span>\n<span class=\"token number\">2</span>    <span class=\"token punctuation\">(</span><span class=\"token number\">8</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">9</span><span class=\"token punctuation\">)</span>\ndtype<span class=\"token punctuation\">:</span> <span class=\"token builtin\">object</span></code></pre>\n\n<p>​\t\t顺带提一下，如果 <code>reult_type=&quot;broadcast&quot;</code>，那么原 column 和 index 名会继承到新生成的数据中。仔细对比上下两次的运行，你就能发现不同的表现了。</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">func</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> x<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span>\n\ndf<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span>func<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> result_type<span class=\"token operator\">=</span><span class=\"token string\">'broadcast'</span><span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">   A  B\n0  8 -9\n1  8 -9\n2  8 -9</code></pre>\n\n<p>​\t\t如果只想改一个column：</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">func</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> x<span class=\"token punctuation\">[</span><span class=\"token string\">\"A\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> <span class=\"token number\">4</span>\n  \ndf<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span>func<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">0    16\n1    16\n2    16</code></pre>\n\n<p>​\t\t想要返回原df，但只修改一个column：</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">func</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> x<span class=\"token punctuation\">[</span><span class=\"token string\">\"A\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> <span class=\"token number\">4</span>\n\ndf<span class=\"token punctuation\">[</span><span class=\"token string\">\"A\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> df<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span>func<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\ndf</code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">    A  B\n0  16  9\n1  16  9\n2  16  9</code></pre>\n\n<p>​\t\t想对row进行操作时，修改axis的值为0，并且修改func中对应的运算规则:</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">func</span><span class=\"token punctuation\">(</span>r<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> r<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> <span class=\"token number\">4</span>\n\nlast_row <span class=\"token operator\">=</span> df<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span>func<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"last_row:\\n\"</span><span class=\"token punctuation\">,</span> last_row<span class=\"token punctuation\">)</span>\n\ndf<span class=\"token punctuation\">.</span>iloc<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> last_row\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\ndf:\\n\"</span><span class=\"token punctuation\">,</span> df<span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">last_row:\n A    64\nB    36\ndtype: int64\n\ndf:\n     A   B\n0  16   9\n1  16   9\n2  64  36</code></pre>\n\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>​\t\t想对数据做特殊的运算，甚至想自定义功能，对数据做批量处理，我们今天就介绍了两大类方法，一种是直接索引-运算，一种是利用 pandas 的 apply 来做更为丰富的运算模式。</p>\n<h2 id=\"文字处理\"><a href=\"#文字处理\" class=\"headerlink\" title=\"文字处理\"></a>文字处理</h2><p>​\t\t相比 Python 的科学运算神器 Numpy，Pandas 还有一个特别优势的地方，那就是处理数据库当中的文字信息。 对比 Numpy，Numpy 是一个纯数据处理的库，在数据处理的速度上， 是要优于 Pandas 的。但是在处理数据的丰富度上，比如要处理文字，日期型数据的时候，Pandas 还是有很大优势的。 今天我们就来看看处理文本数据时，Pandas 可以怎么用。</p>\n<h3 id=\"格式化字符\"><a href=\"#格式化字符\" class=\"headerlink\" title=\"格式化字符\"></a>格式化字符</h3><ul>\n<li><code>str.upper(); str.lower(); str.len()</code></li>\n</ul>\n<p>​\t\t需要对标一下Python中自带的文字处理功能：Python本身就有很多自带的文字函数，如<code>strip()</code>，<code>upper()</code>等：</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\npy_s <span class=\"token operator\">=</span> <span class=\"token string\">\"A,B,C,Aaba,Baca,CABA,dog,cat\"</span>\npd_s <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>Series<span class=\"token punctuation\">(</span>\n  <span class=\"token punctuation\">[</span><span class=\"token string\">\"A\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"B\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"C\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"Aaba\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"Baca\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"CABA\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"dog\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"cat\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n  dtype<span class=\"token operator\">=</span><span class=\"token string\">\"string\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"python:\\n\"</span><span class=\"token punctuation\">,</span> py_s<span class=\"token punctuation\">.</span>upper<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\npandas:\\n\"</span><span class=\"token punctuation\">,</span> pd_s<span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>upper<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">python:\n A,B,C,AABA,BACA,CABA,DOG,CAT\n\npandas:\n 0       A\n1       B\n2       C\n3    AABA\n4    BACA\n5    CABA\n6     DOG\n7     CAT\ndtype: string</code></pre>\n\n<p>​\t\t**注意如果要用到 Pandas 丰富的文字处理功能，你要确保 Series 或者 DataFrame 的 <code>dtype=&quot;string&quot;</code>**，如果不是 string， 比如我们刚从一个 excel 中读取出来一个数据，自动读的，没有解析到 string 格式， 我们怎么调整呢？ 其实也简单。</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">pd_not_s <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>Series<span class=\"token punctuation\">(</span>\n  <span class=\"token punctuation\">[</span><span class=\"token string\">\"A\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"B\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"C\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Aaba\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Baca\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"CABA\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"dog\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"cat\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"pd_not_s type:\"</span><span class=\"token punctuation\">,</span> pd_not_s<span class=\"token punctuation\">.</span>dtype<span class=\"token punctuation\">)</span>\n<span class=\"token comment\">#pd_not_s type: object</span>\npd_s <span class=\"token operator\">=</span> pd_not_s<span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span><span class=\"token string\">\"string\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"pd_s type:\"</span><span class=\"token punctuation\">,</span> pd_s<span class=\"token punctuation\">.</span>dtype<span class=\"token punctuation\">)</span>\n<span class=\"token comment\">#pd_s type: string</span></code></pre>\n\n<p>​\t\t好，牢记这点，我们接着来对比原生Python的功能。</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"python lower:\\n\"</span><span class=\"token punctuation\">,</span> py_s<span class=\"token punctuation\">.</span>lower<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\npandas lower:\\n\"</span><span class=\"token punctuation\">,</span> pd_s<span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>lower<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"python len:\\n\"</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> s <span class=\"token keyword\">in</span> py_s<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">\",\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\npandas len:\\n\"</span><span class=\"token punctuation\">,</span> pd_s<span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">python lower:\n a,b,c,aaba,baca,caba,dog,cat\n\npandas lower:\n 0       a\n1       b\n2       c\n3    aaba\n4    baca\n5    caba\n6     dog\n7     cat\ndtype: string\npython len:\n [1, 1, 1, 4, 4, 4, 3, 3]\n\npandas len:\n 0    1\n1    1\n2    1\n3    4\n4    4\n5    4\n6    3\n7    3\ndtype: Int64</code></pre>\n\n<ul>\n<li><code>str.strip(); str.lstrip(); str.rstrip()</code></li>\n</ul>\n<p>​\t\t再来对比一下对文字的裁剪：</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">py_s <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"   jack\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"jill \"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"    jesse    \"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"frank\"</span><span class=\"token punctuation\">]</span>\npd_s <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>Series<span class=\"token punctuation\">(</span>py_s<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span><span class=\"token string\">\"string\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"python strip:\\n\"</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>s<span class=\"token punctuation\">.</span>strip<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> s <span class=\"token keyword\">in</span> py_s<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\npandas strip:\\n\"</span><span class=\"token punctuation\">,</span> pd_s<span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>strip<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\n\\npython lstrip:\\n\"</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>s<span class=\"token punctuation\">.</span>lstrip<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> s <span class=\"token keyword\">in</span> py_s<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\npandas lstrip:\\n\"</span><span class=\"token punctuation\">,</span> pd_s<span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>lstrip<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\n\\npython rstrip:\\n\"</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>s<span class=\"token punctuation\">.</span>rstrip<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> s <span class=\"token keyword\">in</span> py_s<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\npandas rstrip:\\n\"</span><span class=\"token punctuation\">,</span> pd_s<span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>rstrip<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">python strip:\n [&#39;jack&#39;, &#39;jill&#39;, &#39;jesse&#39;, &#39;frank&#39;]\n\npandas strip:\n 0     jack\n1     jill\n2    jesse\n3    frank\ndtype: string\n\n\npython lstrip:\n [&#39;jack&#39;, &#39;jill &#39;, &#39;jesse    &#39;, &#39;frank&#39;]\n\npandas lstrip:\n 0         jack\n1        jill \n2    jesse    \n3        frank\ndtype: string\n\n\npython rstrip:\n [&#39;   jack&#39;, &#39;jill&#39;, &#39;    jesse&#39;, &#39;frank&#39;]\n\npandas rstrip:\n 0         jack\n1         jill\n2        jesse\n3        frank\ndtype: string</code></pre>\n\n<ul>\n<li><code>str.split()</code></li>\n</ul>\n<p>​\t\t从结果可能看不清空白符有多少，但是实际上是把空白符都移除掉了。下面再对比一下<code>split</code>拆分方法。</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">pt_s <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"a_b_c\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"jill_jesse\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"frank\"</span><span class=\"token punctuation\">]</span>\npd_s <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>Series<span class=\"token punctuation\">(</span>py_s<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span><span class=\"token string\">\"string\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"python split:\\n\"</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>s<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">\"_\"</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> s <span class=\"token keyword\">in</span> py_s<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\npandas split:\\n\"</span><span class=\"token punctuation\">,</span> pd_s<span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">\"_\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">python split:\n [[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;], [&#39;jill&#39;, &#39;jesse&#39;], [&#39;frank&#39;]]\n\npandas split:\n 0        [a, b, c]\n1    [jill, jesse]\n2          [frank]\ndtype: object</code></pre>\n\n<p>​\t\t咦，pandas 这样拆分起来怪怪的，把结果都放到了一个 column 里面，我还记得上一节用 <code>apply()</code> 的时候，我可以加一个 <code>result_type=&quot;expand&quot;</code>，同样，在 <code>split</code> 中也有类似的功能，可以将拆分出来的结果放到不同的 column 中去。</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">pd_s<span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">\"_\"</span><span class=\"token punctuation\">,</span> expand<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">       0      1     2\n0      a      b     c\n1   jill  jesse  &lt;NA&gt;\n2  frank   &lt;NA&gt;  &lt;NA&gt;</code></pre>\n\n<p>​\t\t你看，一共拆出了三个 column，但是有些 column 因为没有 split 出那么多值，所以显示的也是 <code>pd.nan</code></p>\n<p>​\t\t这里还有一点我想说，我们上面都是在 <code>Series</code> 里面做实验，其实 <code>DataFrame</code> 也是一样的。 <strong>你要做的，只是先选一个 column 或者 row，拿到一个 Series 再开始做 str 的处理</strong></p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">pd_df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"a\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"b\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"C\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"D\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\npd_df<span class=\"token punctuation\">.</span>iloc<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>upper<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">0    A\n1    B\nName: 0, dtype: object</code></pre>\n\n\n\n<h3 id=\"正则方案\"><a href=\"#正则方案\" class=\"headerlink\" title=\"正则方案\"></a>正则方案</h3><ul>\n<li><code>str.contains(); str.match(); </code></li>\n</ul>\n<p>​\t\t正则是一个很有用的东西，我们在Python 基础中也花了大功夫来学习正则表达式， 用特殊规则获取到特殊的文本。在演示的第一件事情就是它是否真的可以找到一些东西。我们用 <code>str.contains()</code> 或 <code>str.match()</code> 来确认它真的找到了匹配文字。</p>\n<p>​\t\t注意，如果你还不了解正则表达式，我强烈建议你先看一下我的正则教学。 要不然你也看不懂我写的匹配规则，比如这里 <code>[0-9][a-z]</code> 表示要匹配 0<del>9 的任何数字，之后再接着匹配 a</del>z 的任何字母。</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">pattern <span class=\"token operator\">=</span> <span class=\"token string\">r\"[0-9][a-z]\"</span>\ns <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>Series<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"1\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"1a\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"11c\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"abc\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span><span class=\"token string\">\"string\"</span><span class=\"token punctuation\">)</span>\ns<span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>contains<span class=\"token punctuation\">(</span>pattern<span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">0    False\n1     True\n2     True\n3    False\ndtype: boolean</code></pre>\n\n<p>​\t\t现在请你把 <code>str.contains()</code> 换成 <code>str.match()</code> 看看结果有无变化。仔细的你肯定发现了，<code>11c</code> 这个字符，用 <code>contains()</code> 可以匹配， 但是 <code>match()</code> 却不能。那是因为 <strong>只要包含正则规则，<code>contains</code> 就为 True， 但是 <code>match()</code> 的意思是你的正则规则要完全匹配才会返回 True。</strong></p>\n<p>那么为了要让 <code>match</code> 匹配 <code>11c</code> 我们就需要把规则改成 <code>r&quot;[0-9]+?[a-z]</code>。至于为什么， 那请看到我的正则教学。</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">pattern <span class=\"token operator\">=</span> <span class=\"token string\">r\"[0-9]+?[a-z]\"</span>\ns<span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span><span class=\"token keyword\">match</span><span class=\"token punctuation\">(</span>pattern<span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">0    False\n1     True\n2     True\n3    False\ndtype: boolean</code></pre>\n\n<ul>\n<li><code>str.startswith(); str.endswith()</code></li>\n</ul>\n<p>​\t\t下面我们在对比下原生 Python 中我比较常用的 <code>startswith</code>, <code>endswith</code> 这两个前后匹配。</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">py_s <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"1\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"1a\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"21c\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"abc\"</span><span class=\"token punctuation\">]</span>\npd_s <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>Series<span class=\"token punctuation\">(</span>py_s<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span><span class=\"token string\">\"string\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"py_s startswith '1':\\n\"</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>s<span class=\"token punctuation\">.</span>startswith<span class=\"token punctuation\">(</span><span class=\"token string\">\"1\"</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> s <span class=\"token keyword\">in</span> py_s<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\npy_s endswith 'c':\\n\"</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>s<span class=\"token punctuation\">.</span>endswith<span class=\"token punctuation\">(</span><span class=\"token string\">\"c\"</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> s <span class=\"token keyword\">in</span> py_s<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\n\\npd_s startswith '1':\\n\"</span><span class=\"token punctuation\">,</span> pd_s<span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>startswith<span class=\"token punctuation\">(</span><span class=\"token string\">\"1\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\npd_s endswith 'c':\\n\"</span><span class=\"token punctuation\">,</span> pd_s<span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>endswith<span class=\"token punctuation\">(</span><span class=\"token string\">\"c\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">py_s startswith &#39;1&#39;:\n [True, True, False, False]\n\npy_s endswith &#39;c&#39;:\n [False, False, True, True]\n\n\npd_s startswith &#39;1&#39;:\n 0     True\n1     True\n2    False\n3    False\ndtype: boolean\n\npd_s endswith &#39;c&#39;:\n 0    False\n1    False\n2     True\n3     True\ndtype: boolean</code></pre>\n\n<p>​\t\t当然，pandas 的 <code>str.startswith()</code> 和 <code>str.endswith()</code> 都是可以支持正则的。使用方式和上面的 <code>str.match()</code> 等一样。</p>\n<ul>\n<li><code>str.replace()</code></li>\n</ul>\n<p>​\t\t还有一个十分有用，而且我觉得是最重要的，就是 <code>replace</code> 了，因为这真的减轻了我们很多复制粘贴的工作，比如 Excel 中人工按照一个规则修改老板给的新任务。 下面同样，我们对比 Python 原生的 replace，来验证一下。</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">py_s <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"1\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"1a\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"21c\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"abc\"</span><span class=\"token punctuation\">]</span>\npd_s <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>Series<span class=\"token punctuation\">(</span>py_s<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span><span class=\"token string\">\"string\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"py_s replace '1' -> '9':\\n\"</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>s<span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">\"1\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"9\"</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> s <span class=\"token keyword\">in</span> py_s<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\n\\npd_s replace '1' -> '9':\\n\"</span><span class=\"token punctuation\">,</span> pd_s<span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">\"1\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"9\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">py_s replace &#39;1&#39; -&gt; &#39;9&#39;:\n [&#39;9&#39;, &#39;9a&#39;, &#39;29c&#39;, &#39;abc&#39;]\n\n\npd_s replace &#39;1&#39; -&gt; &#39;9&#39;:\n 0      9\n1     9a\n2    29c\n3    abc\ndtype: string</code></pre>\n\n<p>​\t\t但是比原生 Python 强大的是，这个 replace 是支持正则的。我们把所有数字都替换成这个 <code>NUM</code> 吧。</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"pd_s replace -> 'NUM':\"</span><span class=\"token punctuation\">)</span>\npd_s<span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">r\"[0-9]\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"NUM\"</span><span class=\"token punctuation\">,</span> regex<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">pd_s replace -&gt; &#39;NUM&#39;:\n0        NUM\n1       NUMa\n2    NUMNUMc\n3        abc\ndtype: string</code></pre>\n\n<ul>\n<li><code>str.extract(); str.extractall()</code></li>\n</ul>\n<p>​\t\t\t\t除了替换原本文字里的东西，我们还可以去从原本文字里找到特定的文字。有点像正则中的 <code>findall</code> 函数。</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">s <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>Series<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'a1'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'b2'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'c3'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\ns<span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>extract<span class=\"token punctuation\">(</span><span class=\"token string\">r\"([ab])(\\d)\"</span><span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t<code>r&quot;([ab])(\\d)&quot;</code> 这一个正则匹配我简单介绍一下，其中有两个括号，第一个括号是想提取的第一种规则，第二个是第二种想提取的规则。 那么运行出来，你会看到有两个 column，分别对应着这两个提取规则出来的值。最后一行出来的结果是两个 NaN，也就意味着第三个数据没有提取出来任何东西。</p>\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">     0    1\n0    a    1\n1    b    2\n2  NaN  NaN</code></pre>\n\n<p>​\t\t对应 <code>str.extract()</code> 还有一个 <code>str.extractall()</code> 函数，用来返回所有匹配，而不是第一次发现的匹配。</p>\n<h3 id=\"拼接\"><a href=\"#拼接\" class=\"headerlink\" title=\"拼接\"></a>拼接</h3><ul>\n<li><code>str.cat()</code></li>\n</ul>\n<p>​\t\t将两个文本 Series 拼接到一起的方法多种多样。大多情况我们是想结合两个 Series 而形成一个新的 Series。比如下面这样。</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">s1 <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>Series<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"A\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"B\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"C\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"D\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span><span class=\"token string\">\"string\"</span><span class=\"token punctuation\">)</span>\ns2 <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>Series<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"1\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"2\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"3\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"4\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span><span class=\"token string\">\"string\"</span><span class=\"token punctuation\">)</span>\ns1<span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>cat<span class=\"token punctuation\">(</span>s2<span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t上面这是将两个文字拼接成新的文字，如果你想了解如何在 pandas 中做 df 的数据上的拼接，比如 2 columns 和 3 columns 的 df 做横向拼接等， 我们会在这节 Pandas 的拼接专门讲到，因为里面涉及的拼接方法实在是太多了， 在这里讲不完。</p>\n<h3 id=\"总结-1\"><a href=\"#总结-1\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>​\t\t可以看到，文字处理包罗万象，有很多方法。我们挑重点的，调有用的。如果觉得这些对于你还不够， 你可以参考到<a href=\"https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html\">官方文档</a>，获取到更多信息。</p>\n<h2 id=\"异常数据处理\"><a href=\"#异常数据处理\" class=\"headerlink\" title=\"异常数据处理\"></a>异常数据处理</h2><p>​\t\t异常数据，我常代指的是机器学习或者是统计分析中的脏数据。为什么他们异常或者脏呢？ 是因为这些数据不符合你期望当中的规律，给你或你的模型带来困扰。而且很可能是收集数据时，</p>\n<p>​\t\t因为人工差错、机器传感器差错而导致的数据异常。再或者某一个 sample 的数据没有被采集，这也会引发数据批量处理中的异常。</p>\n<p>​\t\t既然数据异常经常发生，又无可避免，我们就来看看如何能找到合适的解决方案。</p>\n","more":"<h2 id=\"运算方法\"><a href=\"#运算方法\" class=\"headerlink\" title=\"运算方法\"></a>运算方法</h2><p>​\t\t我们已经提过如何用Pandas有效地筛选数据，也知道一些基本的统计学运算方法，而在这一节中，我们想要关注的是在Pandas中如何运算。</p>\n<h3 id=\"筛选赋值运算\"><a href=\"#筛选赋值运算\" class=\"headerlink\" title=\"筛选赋值运算\"></a>筛选赋值运算</h3><p>​\t\t在之前筛选数据的教学中，我们能成功找出数据中的某个部分，那么针对这个找出的部分，我们对它进行操作也是没问题的。比如下面我们先生成一组数据，然后再对这组数据进行筛选运算。</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\ndata <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">12</span><span class=\"token punctuation\">,</span> <span class=\"token number\">12</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">6</span><span class=\"token punctuation\">,</span><span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ndf <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>\n  data<span class=\"token punctuation\">,</span>\n  index<span class=\"token operator\">=</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"abcdef\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n  columns<span class=\"token operator\">=</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"ABCD\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ndf</code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">    A   B   C   D\na -12 -11 -10  -9\nb  -8  -7  -6  -5\nc  -4  -3  -2  -1\nd   0   1   2   3\ne   4   5   6   7\nf   8   9  10  11</code></pre>\n\n<p>​\t\t筛选出<code>A</code>的column出来，对<code>A</code>的内容进行乘0的运算。</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">df<span class=\"token punctuation\">[</span><span class=\"token string\">\"A\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*=</span> <span class=\"token number\">0</span>\ndf</code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">   A   B   C   D\na  0 -11 -10  -9\nb  0  -7  -6  -5\nc  0  -3  -2  -1\nd  0   1   2   3\ne  0   5   6   7\nf  0   9  10  11</code></pre>\n\n<p>​\t\t同样，在筛选数据教学中我们提到的<code>iloc</code>,<code>loc</code>功能也是可以用来对某数据进行运算的。<code>iloc</code>找的是index，<code>loc</code>找的是标签。</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">df<span class=\"token punctuation\">.</span>loc<span class=\"token punctuation\">[</span><span class=\"token string\">\"a\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"A\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">100</span>\ndf<span class=\"token punctuation\">.</span>iloc<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">200</span>\ndf</code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">     A   B   C   D\na  100 -11 -10  -9\nb  200  -7  -6  -5\nc    0  -3  -2  -1\nd    0   1   2   3\ne    0   5   6   7\nf    0   9  10  11</code></pre>\n\n<p>​\t\t这只是赋值，现在你拿这些赋值的方法进行运算试试：</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">df<span class=\"token punctuation\">.</span>loc<span class=\"token punctuation\">[</span><span class=\"token string\">\"a\"</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> df<span class=\"token punctuation\">.</span>loc<span class=\"token punctuation\">[</span><span class=\"token string\">\"a\"</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> <span class=\"token number\">2</span>\ndf</code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">     A   B   C   D\na  200 -22 -20 -18\nb  200  -7  -6  -5\nc    0  -3  -2  -1\nd    0   1   2   3\ne    0   5   6   7\nf    0   9  10  11</code></pre>\n\n<p>​\t\t试一试条件运算，下面做的就是对于<code>df[&quot;A&quot;]</code>，我要找出<code>df[&quot;A&quot;]</code>中等于0的数，把这些数赋值成-1.</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">df<span class=\"token punctuation\">[</span><span class=\"token string\">\"A\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>df<span class=\"token punctuation\">[</span><span class=\"token string\">\"A\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span>\ndf</code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">     A   B   C   D\na  200 -22 -20 -18\nb  200  -7  -6  -5\nc   -1  -3  -2  -1\nd   -1   1   2   3\ne   -1   5   6   7\nf   -1   9  10  11</code></pre>\n\n<p>​\t\t基本上，pandas 中可以用于筛选数据的方法都可以用来进一步把筛选出来的数据赋予新的值。</p>\n<h3 id=\"Apply方法\"><a href=\"#Apply方法\" class=\"headerlink\" title=\"Apply方法\"></a>Apply方法</h3><p>​\t\t另一种比较方便的批处理数据的方法，我比较喜欢用的是 <code>apply</code>。这是一种可以针对数据做自定义功能的运算。意味着可以简化数据做复杂的功能运算。 上面我们提到的筛选运算，其实是一种简单的运算方式，如果当运算变得复杂，甚至还需要很多局部变量来缓存运算结果，我们就可以尝试把运算过程放置在一个 <code>func</code> 中， 模块化。</p>\n<p>​\t\t比如我定义下面这批数据：</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">9</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> columns<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'A'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'B'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\ndf</code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">   A  B\n0  4  9\n1  4  9\n2  4  9</code></pre>\n\n<p>​\t\t如果对<code>df</code>做全量的平方根计算，一般的方法是这样：</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">np<span class=\"token punctuation\">.</span>sqrt<span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t但是如果用<code>apply</code>，就会变成</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">df<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>sqrt<span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">     A    B\n0  2.0  3.0\n1  2.0  3.0\n2  2.0  3.0</code></pre>\n\n<p>​\t\t我们把<code>np.sqrt</code>这个函数当成一个参数传入了<code>apply</code>，看起来好像没什么用，还不如直接使用<code>np.sqrt(df)</code>来的方便。的确这个case写成<code>np.sqrt(df)</code>是要简单点。但是下面这种case呢？</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">func</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> x<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span>\n\ndf<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span>func<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> result_type<span class=\"token operator\">=</span><span class=\"token string\">'expand'</span><span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">   0  1\n0  8 -9\n1  8 -9\n2  8 -9</code></pre>\n\n<p>​\t\t在这个自定义的函数中，对 <code>df</code> 中的每一行，每行第 0 位乘以 2，第 1 位乘以 -1，我们原本的 col0，就都乘了 2，而 col1 就都乘了-1。提示一下，<code>apply</code> 里面还有不同的参数项可以选，我使用了一个 <code>result_type=&quot;expand&quot;</code> 的配置，让输出的结果可以生成多 column，要不然， 会只生成一个 column，所有的结果都写在这一个 column 里。要不你试试删除刚才写的 <code>result_type</code>，观察一下生成结果的变化。</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token comment\">#df.apply(func, axis=1)</span>\n<span class=\"token number\">0</span>    <span class=\"token punctuation\">(</span><span class=\"token number\">8</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">9</span><span class=\"token punctuation\">)</span>\n<span class=\"token number\">1</span>    <span class=\"token punctuation\">(</span><span class=\"token number\">8</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">9</span><span class=\"token punctuation\">)</span>\n<span class=\"token number\">2</span>    <span class=\"token punctuation\">(</span><span class=\"token number\">8</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">9</span><span class=\"token punctuation\">)</span>\ndtype<span class=\"token punctuation\">:</span> <span class=\"token builtin\">object</span></code></pre>\n\n<p>​\t\t顺带提一下，如果 <code>reult_type=&quot;broadcast&quot;</code>，那么原 column 和 index 名会继承到新生成的数据中。仔细对比上下两次的运行，你就能发现不同的表现了。</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">func</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> x<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span>\n\ndf<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span>func<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> result_type<span class=\"token operator\">=</span><span class=\"token string\">'broadcast'</span><span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">   A  B\n0  8 -9\n1  8 -9\n2  8 -9</code></pre>\n\n<p>​\t\t如果只想改一个column：</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">func</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> x<span class=\"token punctuation\">[</span><span class=\"token string\">\"A\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> <span class=\"token number\">4</span>\n  \ndf<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span>func<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">0    16\n1    16\n2    16</code></pre>\n\n<p>​\t\t想要返回原df，但只修改一个column：</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">func</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> x<span class=\"token punctuation\">[</span><span class=\"token string\">\"A\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> <span class=\"token number\">4</span>\n\ndf<span class=\"token punctuation\">[</span><span class=\"token string\">\"A\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> df<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span>func<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\ndf</code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">    A  B\n0  16  9\n1  16  9\n2  16  9</code></pre>\n\n<p>​\t\t想对row进行操作时，修改axis的值为0，并且修改func中对应的运算规则:</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">func</span><span class=\"token punctuation\">(</span>r<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> r<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> <span class=\"token number\">4</span>\n\nlast_row <span class=\"token operator\">=</span> df<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span>func<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"last_row:\\n\"</span><span class=\"token punctuation\">,</span> last_row<span class=\"token punctuation\">)</span>\n\ndf<span class=\"token punctuation\">.</span>iloc<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> last_row\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\ndf:\\n\"</span><span class=\"token punctuation\">,</span> df<span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">last_row:\n A    64\nB    36\ndtype: int64\n\ndf:\n     A   B\n0  16   9\n1  16   9\n2  64  36</code></pre>\n\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>​\t\t想对数据做特殊的运算，甚至想自定义功能，对数据做批量处理，我们今天就介绍了两大类方法，一种是直接索引-运算，一种是利用 pandas 的 apply 来做更为丰富的运算模式。</p>\n<h2 id=\"文字处理\"><a href=\"#文字处理\" class=\"headerlink\" title=\"文字处理\"></a>文字处理</h2><p>​\t\t相比 Python 的科学运算神器 Numpy，Pandas 还有一个特别优势的地方，那就是处理数据库当中的文字信息。 对比 Numpy，Numpy 是一个纯数据处理的库，在数据处理的速度上， 是要优于 Pandas 的。但是在处理数据的丰富度上，比如要处理文字，日期型数据的时候，Pandas 还是有很大优势的。 今天我们就来看看处理文本数据时，Pandas 可以怎么用。</p>\n<h3 id=\"格式化字符\"><a href=\"#格式化字符\" class=\"headerlink\" title=\"格式化字符\"></a>格式化字符</h3><ul>\n<li><code>str.upper(); str.lower(); str.len()</code></li>\n</ul>\n<p>​\t\t需要对标一下Python中自带的文字处理功能：Python本身就有很多自带的文字函数，如<code>strip()</code>，<code>upper()</code>等：</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\npy_s <span class=\"token operator\">=</span> <span class=\"token string\">\"A,B,C,Aaba,Baca,CABA,dog,cat\"</span>\npd_s <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>Series<span class=\"token punctuation\">(</span>\n  <span class=\"token punctuation\">[</span><span class=\"token string\">\"A\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"B\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"C\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"Aaba\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"Baca\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"CABA\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"dog\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"cat\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n  dtype<span class=\"token operator\">=</span><span class=\"token string\">\"string\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"python:\\n\"</span><span class=\"token punctuation\">,</span> py_s<span class=\"token punctuation\">.</span>upper<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\npandas:\\n\"</span><span class=\"token punctuation\">,</span> pd_s<span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>upper<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">python:\n A,B,C,AABA,BACA,CABA,DOG,CAT\n\npandas:\n 0       A\n1       B\n2       C\n3    AABA\n4    BACA\n5    CABA\n6     DOG\n7     CAT\ndtype: string</code></pre>\n\n<p>​\t\t**注意如果要用到 Pandas 丰富的文字处理功能，你要确保 Series 或者 DataFrame 的 <code>dtype=&quot;string&quot;</code>**，如果不是 string， 比如我们刚从一个 excel 中读取出来一个数据，自动读的，没有解析到 string 格式， 我们怎么调整呢？ 其实也简单。</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">pd_not_s <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>Series<span class=\"token punctuation\">(</span>\n  <span class=\"token punctuation\">[</span><span class=\"token string\">\"A\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"B\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"C\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Aaba\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Baca\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"CABA\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"dog\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"cat\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"pd_not_s type:\"</span><span class=\"token punctuation\">,</span> pd_not_s<span class=\"token punctuation\">.</span>dtype<span class=\"token punctuation\">)</span>\n<span class=\"token comment\">#pd_not_s type: object</span>\npd_s <span class=\"token operator\">=</span> pd_not_s<span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span><span class=\"token string\">\"string\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"pd_s type:\"</span><span class=\"token punctuation\">,</span> pd_s<span class=\"token punctuation\">.</span>dtype<span class=\"token punctuation\">)</span>\n<span class=\"token comment\">#pd_s type: string</span></code></pre>\n\n<p>​\t\t好，牢记这点，我们接着来对比原生Python的功能。</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"python lower:\\n\"</span><span class=\"token punctuation\">,</span> py_s<span class=\"token punctuation\">.</span>lower<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\npandas lower:\\n\"</span><span class=\"token punctuation\">,</span> pd_s<span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>lower<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"python len:\\n\"</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> s <span class=\"token keyword\">in</span> py_s<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">\",\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\npandas len:\\n\"</span><span class=\"token punctuation\">,</span> pd_s<span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">python lower:\n a,b,c,aaba,baca,caba,dog,cat\n\npandas lower:\n 0       a\n1       b\n2       c\n3    aaba\n4    baca\n5    caba\n6     dog\n7     cat\ndtype: string\npython len:\n [1, 1, 1, 4, 4, 4, 3, 3]\n\npandas len:\n 0    1\n1    1\n2    1\n3    4\n4    4\n5    4\n6    3\n7    3\ndtype: Int64</code></pre>\n\n<ul>\n<li><code>str.strip(); str.lstrip(); str.rstrip()</code></li>\n</ul>\n<p>​\t\t再来对比一下对文字的裁剪：</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">py_s <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"   jack\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"jill \"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"    jesse    \"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"frank\"</span><span class=\"token punctuation\">]</span>\npd_s <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>Series<span class=\"token punctuation\">(</span>py_s<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span><span class=\"token string\">\"string\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"python strip:\\n\"</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>s<span class=\"token punctuation\">.</span>strip<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> s <span class=\"token keyword\">in</span> py_s<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\npandas strip:\\n\"</span><span class=\"token punctuation\">,</span> pd_s<span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>strip<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\n\\npython lstrip:\\n\"</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>s<span class=\"token punctuation\">.</span>lstrip<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> s <span class=\"token keyword\">in</span> py_s<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\npandas lstrip:\\n\"</span><span class=\"token punctuation\">,</span> pd_s<span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>lstrip<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\n\\npython rstrip:\\n\"</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>s<span class=\"token punctuation\">.</span>rstrip<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> s <span class=\"token keyword\">in</span> py_s<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\npandas rstrip:\\n\"</span><span class=\"token punctuation\">,</span> pd_s<span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>rstrip<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">python strip:\n [&#39;jack&#39;, &#39;jill&#39;, &#39;jesse&#39;, &#39;frank&#39;]\n\npandas strip:\n 0     jack\n1     jill\n2    jesse\n3    frank\ndtype: string\n\n\npython lstrip:\n [&#39;jack&#39;, &#39;jill &#39;, &#39;jesse    &#39;, &#39;frank&#39;]\n\npandas lstrip:\n 0         jack\n1        jill \n2    jesse    \n3        frank\ndtype: string\n\n\npython rstrip:\n [&#39;   jack&#39;, &#39;jill&#39;, &#39;    jesse&#39;, &#39;frank&#39;]\n\npandas rstrip:\n 0         jack\n1         jill\n2        jesse\n3        frank\ndtype: string</code></pre>\n\n<ul>\n<li><code>str.split()</code></li>\n</ul>\n<p>​\t\t从结果可能看不清空白符有多少，但是实际上是把空白符都移除掉了。下面再对比一下<code>split</code>拆分方法。</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">pt_s <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"a_b_c\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"jill_jesse\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"frank\"</span><span class=\"token punctuation\">]</span>\npd_s <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>Series<span class=\"token punctuation\">(</span>py_s<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span><span class=\"token string\">\"string\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"python split:\\n\"</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>s<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">\"_\"</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> s <span class=\"token keyword\">in</span> py_s<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\npandas split:\\n\"</span><span class=\"token punctuation\">,</span> pd_s<span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">\"_\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">python split:\n [[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;], [&#39;jill&#39;, &#39;jesse&#39;], [&#39;frank&#39;]]\n\npandas split:\n 0        [a, b, c]\n1    [jill, jesse]\n2          [frank]\ndtype: object</code></pre>\n\n<p>​\t\t咦，pandas 这样拆分起来怪怪的，把结果都放到了一个 column 里面，我还记得上一节用 <code>apply()</code> 的时候，我可以加一个 <code>result_type=&quot;expand&quot;</code>，同样，在 <code>split</code> 中也有类似的功能，可以将拆分出来的结果放到不同的 column 中去。</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">pd_s<span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">\"_\"</span><span class=\"token punctuation\">,</span> expand<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">       0      1     2\n0      a      b     c\n1   jill  jesse  &lt;NA&gt;\n2  frank   &lt;NA&gt;  &lt;NA&gt;</code></pre>\n\n<p>​\t\t你看，一共拆出了三个 column，但是有些 column 因为没有 split 出那么多值，所以显示的也是 <code>pd.nan</code></p>\n<p>​\t\t这里还有一点我想说，我们上面都是在 <code>Series</code> 里面做实验，其实 <code>DataFrame</code> 也是一样的。 <strong>你要做的，只是先选一个 column 或者 row，拿到一个 Series 再开始做 str 的处理</strong></p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">pd_df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"a\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"b\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"C\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"D\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\npd_df<span class=\"token punctuation\">.</span>iloc<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>upper<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">0    A\n1    B\nName: 0, dtype: object</code></pre>\n\n\n\n<h3 id=\"正则方案\"><a href=\"#正则方案\" class=\"headerlink\" title=\"正则方案\"></a>正则方案</h3><ul>\n<li><code>str.contains(); str.match(); </code></li>\n</ul>\n<p>​\t\t正则是一个很有用的东西，我们在Python 基础中也花了大功夫来学习正则表达式， 用特殊规则获取到特殊的文本。在演示的第一件事情就是它是否真的可以找到一些东西。我们用 <code>str.contains()</code> 或 <code>str.match()</code> 来确认它真的找到了匹配文字。</p>\n<p>​\t\t注意，如果你还不了解正则表达式，我强烈建议你先看一下我的正则教学。 要不然你也看不懂我写的匹配规则，比如这里 <code>[0-9][a-z]</code> 表示要匹配 0<del>9 的任何数字，之后再接着匹配 a</del>z 的任何字母。</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">pattern <span class=\"token operator\">=</span> <span class=\"token string\">r\"[0-9][a-z]\"</span>\ns <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>Series<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"1\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"1a\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"11c\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"abc\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span><span class=\"token string\">\"string\"</span><span class=\"token punctuation\">)</span>\ns<span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>contains<span class=\"token punctuation\">(</span>pattern<span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">0    False\n1     True\n2     True\n3    False\ndtype: boolean</code></pre>\n\n<p>​\t\t现在请你把 <code>str.contains()</code> 换成 <code>str.match()</code> 看看结果有无变化。仔细的你肯定发现了，<code>11c</code> 这个字符，用 <code>contains()</code> 可以匹配， 但是 <code>match()</code> 却不能。那是因为 <strong>只要包含正则规则，<code>contains</code> 就为 True， 但是 <code>match()</code> 的意思是你的正则规则要完全匹配才会返回 True。</strong></p>\n<p>那么为了要让 <code>match</code> 匹配 <code>11c</code> 我们就需要把规则改成 <code>r&quot;[0-9]+?[a-z]</code>。至于为什么， 那请看到我的正则教学。</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">pattern <span class=\"token operator\">=</span> <span class=\"token string\">r\"[0-9]+?[a-z]\"</span>\ns<span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span><span class=\"token keyword\">match</span><span class=\"token punctuation\">(</span>pattern<span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">0    False\n1     True\n2     True\n3    False\ndtype: boolean</code></pre>\n\n<ul>\n<li><code>str.startswith(); str.endswith()</code></li>\n</ul>\n<p>​\t\t下面我们在对比下原生 Python 中我比较常用的 <code>startswith</code>, <code>endswith</code> 这两个前后匹配。</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">py_s <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"1\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"1a\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"21c\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"abc\"</span><span class=\"token punctuation\">]</span>\npd_s <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>Series<span class=\"token punctuation\">(</span>py_s<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span><span class=\"token string\">\"string\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"py_s startswith '1':\\n\"</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>s<span class=\"token punctuation\">.</span>startswith<span class=\"token punctuation\">(</span><span class=\"token string\">\"1\"</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> s <span class=\"token keyword\">in</span> py_s<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\npy_s endswith 'c':\\n\"</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>s<span class=\"token punctuation\">.</span>endswith<span class=\"token punctuation\">(</span><span class=\"token string\">\"c\"</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> s <span class=\"token keyword\">in</span> py_s<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\n\\npd_s startswith '1':\\n\"</span><span class=\"token punctuation\">,</span> pd_s<span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>startswith<span class=\"token punctuation\">(</span><span class=\"token string\">\"1\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\npd_s endswith 'c':\\n\"</span><span class=\"token punctuation\">,</span> pd_s<span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>endswith<span class=\"token punctuation\">(</span><span class=\"token string\">\"c\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">py_s startswith &#39;1&#39;:\n [True, True, False, False]\n\npy_s endswith &#39;c&#39;:\n [False, False, True, True]\n\n\npd_s startswith &#39;1&#39;:\n 0     True\n1     True\n2    False\n3    False\ndtype: boolean\n\npd_s endswith &#39;c&#39;:\n 0    False\n1    False\n2     True\n3     True\ndtype: boolean</code></pre>\n\n<p>​\t\t当然，pandas 的 <code>str.startswith()</code> 和 <code>str.endswith()</code> 都是可以支持正则的。使用方式和上面的 <code>str.match()</code> 等一样。</p>\n<ul>\n<li><code>str.replace()</code></li>\n</ul>\n<p>​\t\t还有一个十分有用，而且我觉得是最重要的，就是 <code>replace</code> 了，因为这真的减轻了我们很多复制粘贴的工作，比如 Excel 中人工按照一个规则修改老板给的新任务。 下面同样，我们对比 Python 原生的 replace，来验证一下。</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">py_s <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"1\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"1a\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"21c\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"abc\"</span><span class=\"token punctuation\">]</span>\npd_s <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>Series<span class=\"token punctuation\">(</span>py_s<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span><span class=\"token string\">\"string\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"py_s replace '1' -> '9':\\n\"</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>s<span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">\"1\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"9\"</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> s <span class=\"token keyword\">in</span> py_s<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\n\\npd_s replace '1' -> '9':\\n\"</span><span class=\"token punctuation\">,</span> pd_s<span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">\"1\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"9\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">py_s replace &#39;1&#39; -&gt; &#39;9&#39;:\n [&#39;9&#39;, &#39;9a&#39;, &#39;29c&#39;, &#39;abc&#39;]\n\n\npd_s replace &#39;1&#39; -&gt; &#39;9&#39;:\n 0      9\n1     9a\n2    29c\n3    abc\ndtype: string</code></pre>\n\n<p>​\t\t但是比原生 Python 强大的是，这个 replace 是支持正则的。我们把所有数字都替换成这个 <code>NUM</code> 吧。</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"pd_s replace -> 'NUM':\"</span><span class=\"token punctuation\">)</span>\npd_s<span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">r\"[0-9]\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"NUM\"</span><span class=\"token punctuation\">,</span> regex<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">pd_s replace -&gt; &#39;NUM&#39;:\n0        NUM\n1       NUMa\n2    NUMNUMc\n3        abc\ndtype: string</code></pre>\n\n<ul>\n<li><code>str.extract(); str.extractall()</code></li>\n</ul>\n<p>​\t\t\t\t除了替换原本文字里的东西，我们还可以去从原本文字里找到特定的文字。有点像正则中的 <code>findall</code> 函数。</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">s <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>Series<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'a1'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'b2'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'c3'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\ns<span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>extract<span class=\"token punctuation\">(</span><span class=\"token string\">r\"([ab])(\\d)\"</span><span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t<code>r&quot;([ab])(\\d)&quot;</code> 这一个正则匹配我简单介绍一下，其中有两个括号，第一个括号是想提取的第一种规则，第二个是第二种想提取的规则。 那么运行出来，你会看到有两个 column，分别对应着这两个提取规则出来的值。最后一行出来的结果是两个 NaN，也就意味着第三个数据没有提取出来任何东西。</p>\n<p>​\t\t运行结果：</p>\n<pre class=\"language-none\"><code class=\"language-none\">     0    1\n0    a    1\n1    b    2\n2  NaN  NaN</code></pre>\n\n<p>​\t\t对应 <code>str.extract()</code> 还有一个 <code>str.extractall()</code> 函数，用来返回所有匹配，而不是第一次发现的匹配。</p>\n<h3 id=\"拼接\"><a href=\"#拼接\" class=\"headerlink\" title=\"拼接\"></a>拼接</h3><ul>\n<li><code>str.cat()</code></li>\n</ul>\n<p>​\t\t将两个文本 Series 拼接到一起的方法多种多样。大多情况我们是想结合两个 Series 而形成一个新的 Series。比如下面这样。</p>\n<pre class=\"language-python\" data-language=\"python\"><code class=\"language-python\">s1 <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>Series<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"A\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"B\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"C\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"D\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span><span class=\"token string\">\"string\"</span><span class=\"token punctuation\">)</span>\ns2 <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>Series<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"1\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"2\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"3\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"4\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span><span class=\"token string\">\"string\"</span><span class=\"token punctuation\">)</span>\ns1<span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>cat<span class=\"token punctuation\">(</span>s2<span class=\"token punctuation\">)</span></code></pre>\n\n<p>​\t\t上面这是将两个文字拼接成新的文字，如果你想了解如何在 pandas 中做 df 的数据上的拼接，比如 2 columns 和 3 columns 的 df 做横向拼接等， 我们会在这节 Pandas 的拼接专门讲到，因为里面涉及的拼接方法实在是太多了， 在这里讲不完。</p>\n<h3 id=\"总结-1\"><a href=\"#总结-1\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>​\t\t可以看到，文字处理包罗万象，有很多方法。我们挑重点的，调有用的。如果觉得这些对于你还不够， 你可以参考到<a href=\"https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html\">官方文档</a>，获取到更多信息。</p>\n<h2 id=\"异常数据处理\"><a href=\"#异常数据处理\" class=\"headerlink\" title=\"异常数据处理\"></a>异常数据处理</h2><p>​\t\t异常数据，我常代指的是机器学习或者是统计分析中的脏数据。为什么他们异常或者脏呢？ 是因为这些数据不符合你期望当中的规律，给你或你的模型带来困扰。而且很可能是收集数据时，</p>\n<p>​\t\t因为人工差错、机器传感器差错而导致的数据异常。再或者某一个 sample 的数据没有被采集，这也会引发数据批量处理中的异常。</p>\n<p>​\t\t既然数据异常经常发生，又无可避免，我们就来看看如何能找到合适的解决方案。</p>","categories":[],"tags":[{"name":"python","path":"api/tags/python.json"},{"name":"机器学习基础","path":"api/tags/机器学习基础.json"}]}