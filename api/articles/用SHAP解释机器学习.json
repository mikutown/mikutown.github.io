{"title":"用SHAP解释机器学习","slug":"用SHAP解释机器学习","date":"2022-08-09T09:41:28.000Z","updated":"2022-08-10T04:34:21.037Z","comments":true,"path":"api/articles/用SHAP解释机器学习.json","excerpt":null,"covers":["http://cdn.leafii.top/img/1*tBYED5khakp0zlEV-mWdfQ.png","http://cdn.leafii.top/img/1*l8aco7sQ4LcjLWFUggBSmg.png","http://cdn.leafii.top/img/1*RxUaGj_RH6FfCSwklWQVzA.png","http://cdn.leafii.top/img/1*Q8KsY0ehupv_VxMzYcHWTg.png"],"content":"<h1 id=\"用SHAP解释机器学习\"><a href=\"#用SHAP解释机器学习\" class=\"headerlink\" title=\"用SHAP解释机器学习\"></a>用SHAP解释机器学习</h1><h2 id=\"什么是Explainable-AI？\"><a href=\"#什么是Explainable-AI？\" class=\"headerlink\" title=\"什么是Explainable AI？\"></a>什么是Explainable AI？</h2><p>关于要如何解释自己模型预测出来的结果，我们都需要了解为何我们训练出的模型会做出如此判断，是基于什么原因作出这种判断，会不会model完全用了非常诡异的特征去下决策（但说不定是对的？）以下归纳出几个我们为什么想知道我们训练出来的模型到底在说什么？</p>\n<ul>\n<li>确认模型的合理性：在我们需要做出决策，倚重模型做判断时，我们需要知道，这个模型所参考的数据特征是否正如我们想象的一样。若我们不知道演算法建议的理由，那下决策肯定会觉得害怕，如同依赖了一个名为AI的黑盒子一般。</li>\n<li>改良模型：这点其实和第一点略为相同，如果我们能知道我们的模型所预测的依据，我们就可以去试着改善它。特别是当模型和资料中，存在了一些恰恰好的bias，若我们没试着看背后的原因的话，通常很难发现一些问题。以过去的专案经验当作例子，我们使用影像检验在找瑕疵物件时，预测的效果不错，但取细看背后的原因，却发现模型依赖背景而做出决断。详细的情况是物件的缺陷在拍摄当天时有个固定的光影，模型判断defect的依据竟然是用那个光影，而非物件上的瑕疵。</li>\n<li>从模型上学习：当模型真正的从品质良好的训练资料集中得到了有用的判断依据，人类就可以从模型中学到一些东西。例如为期，人类目前很显然已经被AI击败，但在无关输赢的时候，职业棋手目前早已寻求AI的帮助，让自己的技术更上一层楼。</li>\n</ul>\n<h2 id=\"SHAP-Value\"><a href=\"#SHAP-Value\" class=\"headerlink\" title=\"SHAP Value\"></a>SHAP Value</h2><p>以上几点让我们了解Explainable AI的必要性，那我们该如何下手去理解每个预测我们的模型是如何理解的呢？</p>\n<p>SHAP values（SHapley Additive exPlanations）是一个Python的视觉化分析套件，让我们能轻易地了解我们的模型做出决策的依据。</p>\n<p>那对我们来说，什么时候该用SHAP value呢？</p>\n<p>举例：</p>\n<ul>\n<li>制造业的入料控制以达到最佳化结果，你如何正确地减少不必要的入料，也可以达到一样的产能。</li>\n<li>利用Users的使用行为，找到诈骗账号。并对模型做出解释，借此在各种features中找到诈骗账号一般性具有的行为。</li>\n</ul>\n<h2 id=\"SHAP估计\"><a href=\"#SHAP估计\" class=\"headerlink\" title=\"SHAP估计\"></a>SHAP估计</h2><p>除了这个方法，还可以使用SHAP（SHapley Additive exPlanations）来估计Shapley values，SHAP将模型的预测值解释为每个输入特征的归因值之和。换句话说，就是计算每一个特征的Shapley value，依此来衡量特征对最终预测值的影响。用公式表示：</p>\n<p>$$g(z’)&#x3D;\\phi_0+\\sum_{j&#x3D;1}^{M}\\phi_jz’_j$$</p>\n<ul>\n<li>g(z’)为被简化的可解释的模型</li>\n<li>z’表示相应的特征是否存在（1或0），M是输入特征的个数，因此可以表示成$z’\\in{0,1}^M$</li>\n<li>$\\phi_i$代表我们要求的Shapley value</li>\n<li>$\\phi_0$代表平均值</li>\n</ul>\n<h2 id=\"Kernel-SHAP\"><a href=\"#Kernel-SHAP\" class=\"headerlink\" title=\"Kernel SHAP\"></a>Kernel SHAP</h2><p>$$g(z’)&#x3D;\\phi_0+\\sum_{k&#x3D;1}^{M}\\phi_kz’_k$$</p>\n<p>Kernel SHAP 的计算流程：</p>\n<ul>\n<li>Sample coalitions $z’_k\\in{0,1}^M,k\\in{1,…,K}$(1&#x3D;feature present in coalition,0 &#x3D; feature absent).</li>\n<li>Get prediction for each $z’_k$ by first converting z’k to the original feature space and then applying model f:$f(h_x(z’_k))$</li>\n<li>Compute the weight for each $z’_k$ with the SHAP kernel.</li>\n<li>Fit weighted linear model.</li>\n<li>Return Shapley values $\\phi_k$, the coefficients from the linear model.</li>\n</ul>\n<p>Kernel SHAP 计算流程的详细说明：</p>\n<p>Step 1:</p>\n<ul>\n<li>Sample coalitions $z’_k\\in{0,1}^M,k\\in{1,…,K}$(1&#x3D;feature present in coalition,0 &#x3D; feature absent).</li>\n</ul>\n<p>我们只想要求Age的Shapley value，而Weight和Color都嫌不要求，因此将Age，Weight，Color的z设为（1，0，0）</p>\n<p><img src=\"http://cdn.leafii.top/img/1*tBYED5khakp0zlEV-mWdfQ.png\" alt=\"Step 1\" loading=\"lazy\"></p>\n<p>Step 2:</p>\n<ul>\n<li>Get prediction for each $z’_k$ by first converting z’k to the original feature space and then applying model f:$f(h_x(z’_k))$</li>\n</ul>\n<p>我们取得DATA里的值，假设有一笔资料的Age，Weight，Color为0.5,20,Blue,由于我们Age，Weight，Color的z设为（1，0，0），因此只需保留Age的正确性（0.5），其他两个都随机替代其他资料存在的值，例如Weight从20换成17，Color从Blue换成Pink，注意，17和Pink必须要是DATA里有存在的值，不能随机填。</p>\n<p><img src=\"http://cdn.leafii.top/img/1*l8aco7sQ4LcjLWFUggBSmg.png\" alt=\"Step 2\" loading=\"lazy\"></p>\n<p>Step 3:</p>\n<ul>\n<li>Compute the weight for each $z’_k$ with the SHAP kernel.</li>\n</ul>\n<p>Kernel SHAP中权重的计算根据Simplified Features中0或1的数量，若有很多0或是很多1，我们取较高的权重，若0和1的数量相近则取较低的权重。</p>\n<p><img src=\"http://cdn.leafii.top/img/1*RxUaGj_RH6FfCSwklWQVzA.png\" alt=\"Step 3\" loading=\"lazy\"></p>\n<p>Step 4:</p>\n<ul>\n<li>Fit weighted linear model.</li>\n</ul>\n<p>最后再根据资料来fit一个weighted linear model，而获得的weight其实就是特征对应的Shapley values</p>\n<p><img src=\"http://cdn.leafii.top/img/1*Q8KsY0ehupv_VxMzYcHWTg.png\" alt=\"Step 4\" loading=\"lazy\"></p>\n<h2 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2><p>[1] <a href=\"https://medium.com/ai-academy-taiwan/%E5%8F%AF%E8%A7%A3%E9%87%8B-ai-xai-%E7%B3%BB%E5%88%97-shap-2c600b4bdc9e\">可解釋 AI (XAI) 系列 — SHAP</a></p>\n","more":"<h1 id=\"用SHAP解释机器学习\"><a href=\"#用SHAP解释机器学习\" class=\"headerlink\" title=\"用SHAP解释机器学习\"></a>用SHAP解释机器学习</h1><h2 id=\"什么是Explainable-AI？\"><a href=\"#什么是Explainable-AI？\" class=\"headerlink\" title=\"什么是Explainable AI？\"></a>什么是Explainable AI？</h2><p>关于要如何解释自己模型预测出来的结果，我们都需要了解为何我们训练出的模型会做出如此判断，是基于什么原因作出这种判断，会不会model完全用了非常诡异的特征去下决策（但说不定是对的？）以下归纳出几个我们为什么想知道我们训练出来的模型到底在说什么？</p>\n<ul>\n<li>确认模型的合理性：在我们需要做出决策，倚重模型做判断时，我们需要知道，这个模型所参考的数据特征是否正如我们想象的一样。若我们不知道演算法建议的理由，那下决策肯定会觉得害怕，如同依赖了一个名为AI的黑盒子一般。</li>\n<li>改良模型：这点其实和第一点略为相同，如果我们能知道我们的模型所预测的依据，我们就可以去试着改善它。特别是当模型和资料中，存在了一些恰恰好的bias，若我们没试着看背后的原因的话，通常很难发现一些问题。以过去的专案经验当作例子，我们使用影像检验在找瑕疵物件时，预测的效果不错，但取细看背后的原因，却发现模型依赖背景而做出决断。详细的情况是物件的缺陷在拍摄当天时有个固定的光影，模型判断defect的依据竟然是用那个光影，而非物件上的瑕疵。</li>\n<li>从模型上学习：当模型真正的从品质良好的训练资料集中得到了有用的判断依据，人类就可以从模型中学到一些东西。例如为期，人类目前很显然已经被AI击败，但在无关输赢的时候，职业棋手目前早已寻求AI的帮助，让自己的技术更上一层楼。</li>\n</ul>\n<h2 id=\"SHAP-Value\"><a href=\"#SHAP-Value\" class=\"headerlink\" title=\"SHAP Value\"></a>SHAP Value</h2><p>以上几点让我们了解Explainable AI的必要性，那我们该如何下手去理解每个预测我们的模型是如何理解的呢？</p>\n<p>SHAP values（SHapley Additive exPlanations）是一个Python的视觉化分析套件，让我们能轻易地了解我们的模型做出决策的依据。</p>\n<p>那对我们来说，什么时候该用SHAP value呢？</p>\n<p>举例：</p>\n<ul>\n<li>制造业的入料控制以达到最佳化结果，你如何正确地减少不必要的入料，也可以达到一样的产能。</li>\n<li>利用Users的使用行为，找到诈骗账号。并对模型做出解释，借此在各种features中找到诈骗账号一般性具有的行为。</li>\n</ul>\n<h2 id=\"SHAP估计\"><a href=\"#SHAP估计\" class=\"headerlink\" title=\"SHAP估计\"></a>SHAP估计</h2><p>除了这个方法，还可以使用SHAP（SHapley Additive exPlanations）来估计Shapley values，SHAP将模型的预测值解释为每个输入特征的归因值之和。换句话说，就是计算每一个特征的Shapley value，依此来衡量特征对最终预测值的影响。用公式表示：</p>\n<p>$$g(z’)&#x3D;\\phi_0+\\sum_{j&#x3D;1}^{M}\\phi_jz’_j$$</p>\n<ul>\n<li>g(z’)为被简化的可解释的模型</li>\n<li>z’表示相应的特征是否存在（1或0），M是输入特征的个数，因此可以表示成$z’\\in{0,1}^M$</li>\n<li>$\\phi_i$代表我们要求的Shapley value</li>\n<li>$\\phi_0$代表平均值</li>\n</ul>\n<h2 id=\"Kernel-SHAP\"><a href=\"#Kernel-SHAP\" class=\"headerlink\" title=\"Kernel SHAP\"></a>Kernel SHAP</h2><p>$$g(z’)&#x3D;\\phi_0+\\sum_{k&#x3D;1}^{M}\\phi_kz’_k$$</p>\n<p>Kernel SHAP 的计算流程：</p>\n<ul>\n<li>Sample coalitions $z’_k\\in{0,1}^M,k\\in{1,…,K}$(1&#x3D;feature present in coalition,0 &#x3D; feature absent).</li>\n<li>Get prediction for each $z’_k$ by first converting z’k to the original feature space and then applying model f:$f(h_x(z’_k))$</li>\n<li>Compute the weight for each $z’_k$ with the SHAP kernel.</li>\n<li>Fit weighted linear model.</li>\n<li>Return Shapley values $\\phi_k$, the coefficients from the linear model.</li>\n</ul>\n<p>Kernel SHAP 计算流程的详细说明：</p>\n<p>Step 1:</p>\n<ul>\n<li>Sample coalitions $z’_k\\in{0,1}^M,k\\in{1,…,K}$(1&#x3D;feature present in coalition,0 &#x3D; feature absent).</li>\n</ul>\n<p>我们只想要求Age的Shapley value，而Weight和Color都嫌不要求，因此将Age，Weight，Color的z设为（1，0，0）</p>\n<p><img src=\"http://cdn.leafii.top/img/1*tBYED5khakp0zlEV-mWdfQ.png\" alt=\"Step 1\"></p>\n<p>Step 2:</p>\n<ul>\n<li>Get prediction for each $z’_k$ by first converting z’k to the original feature space and then applying model f:$f(h_x(z’_k))$</li>\n</ul>\n<p>我们取得DATA里的值，假设有一笔资料的Age，Weight，Color为0.5,20,Blue,由于我们Age，Weight，Color的z设为（1，0，0），因此只需保留Age的正确性（0.5），其他两个都随机替代其他资料存在的值，例如Weight从20换成17，Color从Blue换成Pink，注意，17和Pink必须要是DATA里有存在的值，不能随机填。</p>\n<p><img src=\"http://cdn.leafii.top/img/1*l8aco7sQ4LcjLWFUggBSmg.png\" alt=\"Step 2\"></p>\n<p>Step 3:</p>\n<ul>\n<li>Compute the weight for each $z’_k$ with the SHAP kernel.</li>\n</ul>\n<p>Kernel SHAP中权重的计算根据Simplified Features中0或1的数量，若有很多0或是很多1，我们取较高的权重，若0和1的数量相近则取较低的权重。</p>\n<p><img src=\"http://cdn.leafii.top/img/1*RxUaGj_RH6FfCSwklWQVzA.png\" alt=\"Step 3\"></p>\n<p>Step 4:</p>\n<ul>\n<li>Fit weighted linear model.</li>\n</ul>\n<p>最后再根据资料来fit一个weighted linear model，而获得的weight其实就是特征对应的Shapley values</p>\n<p><img src=\"http://cdn.leafii.top/img/1*Q8KsY0ehupv_VxMzYcHWTg.png\" alt=\"Step 4\"></p>\n<h2 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2><p>[1] <a href=\"https://medium.com/ai-academy-taiwan/%E5%8F%AF%E8%A7%A3%E9%87%8B-ai-xai-%E7%B3%BB%E5%88%97-shap-2c600b4bdc9e\">可解釋 AI (XAI) 系列 — SHAP</a></p>\n","categories":[],"tags":[{"name":"python","path":"api/tags/python.json"},{"name":"机器学习基础","path":"api/tags/机器学习基础.json"},{"name":"博弈论基础","path":"api/tags/博弈论基础.json"}]}