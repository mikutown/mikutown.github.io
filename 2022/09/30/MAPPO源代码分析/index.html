<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="theme-color" content="#0078E7"><meta name="author" content="Leafii"><meta name="copyright" content="Leafii"><meta name="generator" content="Hexo 6.2.0"><meta name="theme" content="hexo-theme-yun"><title>MAPPO源代码分析 | LeafiiのBlog</title><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@900&amp;display=swap" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/star-markdown-css@0.3.3/dist/yun/yun-markdown.min.css"><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/prism-theme-vars/base.css"><script src="//at.alicdn.com/t/font_1140697_dxory92pb0h.js" async></script><script src="https://fastly.jsdelivr.net/npm/@unocss/runtime/mini.global.js"></script><script src="https://fastly.jsdelivr.net/npm/scrollreveal/dist/scrollreveal.min.js" defer></script><script>function initScrollReveal() {
  [".post-card",".markdown-body img"].forEach((target)=> {
    ScrollReveal().reveal(target);
  })
}
document.addEventListener("DOMContentLoaded", initScrollReveal);
document.addEventListener("pjax:success", initScrollReveal);
</script><link rel="stylesheet" type="text/css" href="https://fastly.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script defer src="https://fastly.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script><link rel="stylesheet" type="text/css" href="https://fastly.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.css"><script defer src="https://fastly.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.js"></script><script defer src="https://fastly.jsdelivr.net/npm/katex@latest/dist/contrib/auto-render.min.js"></script><script type="module">import { renderKatex } from '/js/utils.js'
document.addEventListener("DOMContentLoaded", () => {
  renderKatex({
    ...{},
    ...true?.options,
  });
});</script><link rel="icon" type="image/png" href="../../../../favicon.ico"><link rel="mask-icon" href="../../../../favicon.ico" color="#0078E7"><link rel="preload" href="../../../../css/hexo-theme-yun.css" as="style"><link rel="prefetch" href="../../../../js/sidebar.js" as="script"><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><link rel="preconnect" href="https://fastly.jsdelivr.net/npm/" crossorigin><script id="yun-config">
    window.Yun = {}
    window.CONFIG = {"hostname":"leafii.top","root":"/","title":["Leafii","の","博","客"],"version":"1.9.3","mode":"auto","copycode":true,"page":{"isPost":true},"i18n":{"placeholder":"搜索...","empty":"找不到您查询的内容: ${query}","hits":"找到 ${hits} 条结果","hits_time":"找到 ${hits} 条结果（用时 ${time} 毫秒）"},"anonymous_image":"https://cdn.yunyoujun.cn/img/avatar/none.jpg","say":{"api":"https://el-bot-api.vercel.app/api/words/young"},"local_search":{"path":"/search.xml"},"fireworks":{"colors":null},"vendors":{"darken":"https://fastly.jsdelivr.net/npm/darken@1.5.0"}};
  </script><link rel="stylesheet" href="../../../../css/hexo-theme-yun.css"><script src="../../../../js/hexo-theme-yun.js" type="module"></script><link rel="alternate" href="../../../../atom.xml" title="LeafiiのBlog" type="application/atom+xml"><meta name="description" content="代码地址：https:&#x2F;&#x2F;github.com&#x2F;marlbenchmark&#x2F;on-policy 官方出品轻量化mappo代码：https:&#x2F;&#x2F;github.com&#x2F;tinyzqh&#x2F;light_mappo 对应论文：The Surprising Effectiveness of MAPPO in Cooperative, Multi-Agent Games">
<meta property="og:type" content="article">
<meta property="og:title" content="MAPPO源代码分析">
<meta property="og:url" content="2022/09/30/MAPPO%E6%BA%90%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/index.html">
<meta property="og:site_name" content="LeafiiのBlog">
<meta property="og:description" content="代码地址：https:&#x2F;&#x2F;github.com&#x2F;marlbenchmark&#x2F;on-policy 官方出品轻量化mappo代码：https:&#x2F;&#x2F;github.com&#x2F;tinyzqh&#x2F;light_mappo 对应论文：The Surprising Effectiveness of MAPPO in Cooperative, Multi-Agent Games">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://cdn.leafii.top/img/mappo.png">
<meta property="og:image" content="http://cdn.leafii.top/img/image-20221031140635091.png">
<meta property="og:image" content="http://cdn.leafii.top/img/image-20221031141622734.png">
<meta property="og:image" content="http://cdn.leafii.top/img/image-20221031141816194.png">
<meta property="og:image" content="http://cdn.leafii.top/img/image-20221031142025436.png">
<meta property="article:published_time" content="2022-09-30T10:22:03.000Z">
<meta property="article:modified_time" content="2022-10-31T06:36:08.403Z">
<meta property="article:author" content="Leafii">
<meta property="article:tag" content="python">
<meta property="article:tag" content="强化学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://cdn.leafii.top/img/mappo.png"><script>(function() {
  const prefersDark = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches
  const setting = localStorage.getItem('darken-mode') || 'auto'
  if (setting === 'dark' || (prefersDark && setting !== 'light'))
    document.documentElement.classList.toggle('dark', true)
})()</script><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head><body><script defer src="https://fastly.jsdelivr.net/npm/animejs@latest"></script><script defer src="../../../../js/ui/fireworks.js" type="module"></script><canvas class="fireworks"></canvas><div class="container"><a class="sidebar-toggle hty-icon-button" id="menu-btn"><div class="hamburger hamburger--spin" type="button"><span class="hamburger-box"><span class="hamburger-inner"></span></span></div></a><div class="sidebar-toggle sidebar-overlay"></div><aside class="sidebar"><script src="../../../../js/sidebar.js" type="module"></script><ul class="sidebar-nav"><li class="sidebar-nav-item sidebar-nav-toc hty-icon-button sidebar-nav-active" data-target="post-toc-wrap" title="文章目录"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-list-ordered"></use></svg></li><li class="sidebar-nav-item sidebar-nav-overview hty-icon-button" data-target="site-overview-wrap" title="站点概览"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-passport-line"></use></svg></li></ul><div class="sidebar-panel" id="site-overview-wrap"><div class="site-info fix-top"><a class="site-author-avatar" href="../../../../about/" title="Leafii"><img width="96" loading="lazy" src="../../../../images/avatar.jpg" alt="Leafii"></a><div class="site-author-name"><a href="../../../../about/">Leafii</a></div><a class="site-name" href="../../../../about/site.html">LeafiiのBlog</a><sub class="site-subtitle"></sub><div class="site-description"></div></div><nav class="site-state"><a class="site-state-item hty-icon-button icon-home" href="../../../../index.html" title="我的主页"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-home-4-line"></use></svg></span></a><div class="site-state-item"><a href="../../../../archives/" title="归档"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-archive-line"></use></svg></span><span class="site-state-item-count">89</span></a></div><div class="site-state-item"><a href="../../../../categories/" title="分类"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-2-line"></use></svg></span><span class="site-state-item-count">0</span></a></div><div class="site-state-item"><a href="../../../../tags/" title="标签"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="site-state-item-count">24</span></a></div><a class="site-state-item hty-icon-button" target="_blank" rel="noopener" href="https://yun.yunyoujun.cn" title="主题文档"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-settings-line"></use></svg></span></a></nav><hr style="margin-bottom:0.5rem"><div class="links-of-author"><a class="links-of-author-item hty-icon-button" rel="noopener" href="/atom.xml" title="RSS" target="_blank" style="color:orange"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-rss-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://github.com/mikutown" title="GitHub" target="_blank" style="color:#181717"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-github-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="mailto:yunsenye@gmail.com" title="E-Mail" target="_blank" style="color:#8E71C1"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-mail-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://music.163.com/#/user/home?id=299583310" title="网易云音乐" target="_blank" style="color:#C10D0C"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-netease-cloud-music-line"></use></svg></a></div><hr style="margin:0.5rem 1rem"><div class="links"><a class="links-item hty-icon-button" href="../../../../links/" title="友情链接" style="color:dodgerblue"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-genderless-line"></use></svg></a></div><br><a class="links-item hty-icon-button" id="toggle-mode-btn" href="javascript:;" title="Mode" style="color: #f1cb64"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-contrast-2-line"></use></svg></a></div><div class="sidebar-panel sidebar-panel-active" id="post-toc-wrap"><div class="post-toc"><div class="post-toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E8%BF%90%E8%A1%8C"><span class="toc-number">1.</span> <span class="toc-text">代码运行</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MAPPO%E7%AE%97%E6%B3%95%E4%BC%AA%E4%BB%A3%E7%A0%81"><span class="toc-number">2.</span> <span class="toc-text">MAPPO算法伪代码</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E6%95%B4%E4%BD%93%E6%B5%81%E7%A8%8B"><span class="toc-number">3.</span> <span class="toc-text">代码整体流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%87%87%E6%A0%B7%E6%B5%81%E7%A8%8B"><span class="toc-number">4.</span> <span class="toc-text">采样流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B"><span class="toc-number">5.</span> <span class="toc-text">训练流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E8%AE%BE%E8%AE%A1"><span class="toc-number">6.</span> <span class="toc-text">实验设计</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E8%A1%A8%E7%8E%B0%E5%AF%B9%E6%AF%94"><span class="toc-number">6.1.</span> <span class="toc-text">算法表现对比</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#NA-MAPPO%E5%92%8CNV-MAPPO%E7%9A%84%E5%AF%B9%E6%AF%94"><span class="toc-number">6.2.</span> <span class="toc-text">NA-MAPPO和NV-MAPPO的对比</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AD%96%E7%95%A5%E7%86%B5%E5%92%8C%E5%A5%BD%E5%A5%87%E5%BF%83%E6%8E%A2%E7%B4%A2%E7%9A%84%E5%BC%82%E5%90%8C"><span class="toc-number">6.3.</span> <span class="toc-text">策略熵和好奇心探索的异同</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="toc-number">7.</span> <span class="toc-text">参考文献</span></a></li></ol></div></div></div></aside><main class="sidebar-translate" id="content"><div id="post"><article class="hty-card post-block" itemscope itemtype="https://schema.org/Article" style="--smc-primary:#0078E7;"><link itemprop="mainEntityOfPage" href="https:/leafii.top"><span hidden itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="name" content="Leafii"><meta itemprop="description"></span><span hidden itemprop="publisher" itemscope itemtype="https://schema.org/Organization"><meta itemprop="name" content="LeafiiのBlog"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">MAPPO源代码分析</h1><div class="post-meta"><div class="post-time" style="display:block"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-calendar-line"></use></svg></span> <time title="创建时间：2022-09-30 18:22:03" itemprop="dateCreated datePublished" datetime="2022-09-30T18:22:03+08:00">2022-09-30</time><span class="post-meta-divider">-</span><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-calendar-2-line"></use></svg></span> <time title="修改时间：2022-10-31 14:36:08" itemprop="dateModified" datetime="2022-10-31T14:36:08+08:00">2022-10-31</time></div><span class="post-count"><span class="post-symbolcount"><span class="post-meta-item-icon" title="本文字数"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-file-word-line"></use></svg></span> <span title="本文字数">3.5k</span><span class="post-meta-divider">-</span><span class="post-meta-item-icon" title="阅读时长"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-timer-line"></use></svg></span> <span title="阅读时长">15m</span></span></span><div class="post-classify"><span class="post-tag"><a class="tag-item" href="../../../../tags/python/" style="--text-color:var(--hty-text-color)"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">python</span></a><a class="tag-item" href="../../../../tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" style="--text-color:var(--hty-text-color)"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">强化学习</span></a></span></div></div></header><section class="post-body" itemprop="articleBody"><div class="post-content markdown-body"><p>代码地址：<a target="_blank" rel="noopener" href="https://github.com/marlbenchmark/on-policy">https://github.com/marlbenchmark/on-policy</a></p>
<p>官方出品轻量化mappo代码：<a target="_blank" rel="noopener" href="https://github.com/tinyzqh/light_mappo">https://github.com/tinyzqh/light_mappo</a></p>
<p>对应论文：The Surprising Effectiveness of MAPPO in Cooperative, Multi-Agent Games</p>
<span id="more"></span>

<h2 id="代码运行"><a href="#代码运行" class="headerlink" title="代码运行"></a>代码运行</h2><p>使用conda新建环境，python版本推荐为3.6.7，并且安装readme中的MPE环境，然后将pycharm中train_mpe.py文件的configuration中的参数设置为<code>--env_name &quot;MPE&quot; --algorithm_name &quot;rmappo&quot; --experiment_name &quot;check&quot; --scenario_name &quot;simple_spread&quot; --num_agents 3 --num_landmarks 3 --seed 1 --n_training_threads 1 --n_rollout_threads 4 --num_mini_batch 1 --episode_length 25 --num_env_steps 10000 --ppo_epoch 10 --use_ReLU --gain 0.01 --lr 7e-4 --critic_lr 7e-4 --wandb_name &quot;leafii&quot; --user_name &quot;leafii&quot;</code>，以免因为电脑配置不足无法运行。安装其他包时要参考文件夹中requirement.txt中的版本，以免由于版本兼容问题造成代码无法正常运行，debug。</p>
<h2 id="MAPPO算法伪代码"><a href="#MAPPO算法伪代码" class="headerlink" title="MAPPO算法伪代码"></a>MAPPO算法伪代码</h2><p><img src="http://cdn.leafii.top/img/mappo.png" alt="img" loading="lazy"></p>
<p>有两个网络，分别是策略$\pi_{\theta}$和值函数$V_{\phi}$。（作者在文中说如果智能体是同种类的就采用相同的网络参数，对于每个智能体内部也可以采用各自的actor和critic网络，为了符号的便利性，作者直接使用一个网络参数来表示）。值函数$V_{\phi}$需要学习一个映射： $S \rightarrow \mathbb R$。策略函数$\pi_{\theta}$学习一个映射从观测$o_t^{a}$到一个范围的分布或者是映射到一个高斯函数的动作均值和方差用于之后采样动作。</p>
<ul>
<li>Actor的优化目标为：</li>
</ul>
<p>$$L(\theta) &#x3D; [\frac{1}{B_n}\sum_{i&#x3D;1}^{B}\sum_{k-1}^{n}min(r_{\theta,i}^{(k)}A_{i}^{(k)},clip(r_{\theta,i}^{(k)},1-\epsilon,1+\epsilon)A_i^{(k)})]+\sigma \frac{1}{B_n}\sum_{i&#x3D;1}^{B}\sum_{k-1}^{n}S[\pi_{\theta}(o_i^{(k)})],where r_{\theta,i}^{(k)}&#x3D;\frac{\pi_{\theta}(a_i^{(k)}|o_i^{(k)})}{\pi_{\theta_{old}}(a_i^{(k)}|o_i^{(k)})}$$</p>
<p>其中优势函数$A_i^{(k)}$是采用GAE方法的，S表示策略的熵，$\sigma$是控制熵系数的一个超参数。</p>
<ul>
<li>Critic网络优化目标为：</li>
</ul>
<p>$$L(\phi)&#x3D;\frac{1}{B_n}\sum_{i&#x3D;1}^{B}\sum_{k&#x3D;1}^{n}(max[(V_\phi(s_i^{(k)})-\hat R_i)^2,(clip(V_\phi(s_i^{(k)}),V_{\phi_{old}}(s_i^{(k)}-\varepsilon),V_{\phi_{old}}(s_i^{(k)}+\varepsilon)-\hat R_i)^2]$$</p>
<p>其中$\hat R_i$是折扣奖励。B表示batch_size的大小，n表示智能体的数量。</p>
<h2 id="代码整体流程"><a href="#代码整体流程" class="headerlink" title="代码整体流程"></a>代码整体流程</h2><p>每个局部智能体接收一个局部的观察obs，输出一个动作概率，所有的actor智能体都采用一个actor网络。critic网络接收所有智能体的观测obs，<code>cent_obs_space = n * obs_space</code>，其中n为智能体的个数，输出一个V值，V值用于actor的更新。actor的loss和PPO的loss类似，有添加一个熵的loss。Critic的loss更多的是对value的值做normalizer，并且在计算episode的折扣奖励的时候不是单纯的算折扣奖励，有采用gae算折扣回报的方式。</p>
<ul>
<li><p>网络定义</p>
<p>代码定义在<code>onpolicy/algorithms/r_mappo/algorithm/rMAPPOPolicy.py</code></p>
<p>每一个智能体的观测obs_space为一个18维的向量，有3个智能体，cent_obs_space为一个54维的向量，单个智能体的动作空间act_space 为一个离散的5维的向量</p>
</li>
</ul>
<ol>
<li><p>actor</p>
<p>在<code>onpolicy/algorithms/utils/act.py</code>中，输入一个观测（18维），输出一个确切的动作actions和这个动作对数概率。</p>
</li>
</ol>
<pre class="language-python" data-language="python"><code class="language-python">action_dim <span class="token operator">=</span> action_space<span class="token punctuation">.</span>n
self<span class="token punctuation">.</span>action_out <span class="token operator">=</span> Categorical<span class="token punctuation">(</span>inputs_dim<span class="token punctuation">,</span> action_dim<span class="token punctuation">,</span> use_orthogonal<span class="token punctuation">,</span> gain<span class="token punctuation">)</span>
action_logits <span class="token operator">=</span> self<span class="token punctuation">.</span>action_out<span class="token punctuation">(</span>x<span class="token punctuation">,</span> available_actions<span class="token punctuation">)</span>
actions <span class="token operator">=</span> action_logits<span class="token punctuation">.</span>mode<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> deterministic <span class="token keyword">else</span> action_logits<span class="token punctuation">.</span>sample<span class="token punctuation">(</span><span class="token punctuation">)</span> 
action_log_probs <span class="token operator">=</span> action_logits<span class="token punctuation">.</span>log_probs<span class="token punctuation">(</span>actions<span class="token punctuation">)</span></code></pre>

<ol start="2">
<li><p>critic</p>
<p>critic输入维度为<code>cent_obs_space = n * obs_space = 54</code>，输出维度为1。</p>
</li>
</ol>
<pre class="language-python" data-language="python"><code class="language-python">critic_features <span class="token operator">=</span> self<span class="token punctuation">.</span>base<span class="token punctuation">(</span>cent_obs<span class="token punctuation">)</span>
    <span class="token keyword">if</span> self<span class="token punctuation">.</span>_use_naive_recurrent_policy <span class="token keyword">or</span> self<span class="token punctuation">.</span>_use_recurrent_policy<span class="token punctuation">:</span>
        critic_features<span class="token punctuation">,</span> rnn_states <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span>critic_features<span class="token punctuation">,</span> rnn_states<span class="token punctuation">,</span> masks<span class="token punctuation">)</span>
values <span class="token operator">=</span> self<span class="token punctuation">.</span>v_out<span class="token punctuation">(</span>critic_features<span class="token punctuation">)</span></code></pre>

<h2 id="采样流程"><a href="#采样流程" class="headerlink" title="采样流程"></a>采样流程</h2><ul>
<li>初始化obs</li>
</ul>
<p>在on policy&#x2F;scripts&#x2F;train&#x2F;train_mpe.py的make_train_env(all_args)函数中实例化4个环境：</p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">return</span> SubprocVecEnv<span class="token punctuation">(</span><span class="token punctuation">[</span>get_env_fn<span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>all_args<span class="token punctuation">.</span>n_rollout_threads<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>

<p>在onpolicy&#x2F;runner&#x2F;shared&#x2F;mpe_runner.py中的的warmup函数中，如果采用centralized_V值函数的训练方式（？？？），那么需要初始化的时候构造出多个智能体的share_obs：</p>
<pre class="language-python" data-language="python"><code class="language-python">obs <span class="token operator">=</span> self<span class="token punctuation">.</span>envs<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># shape = (4, 3, 18)</span>
share_obs <span class="token operator">=</span> obs<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>self<span class="token punctuation">.</span>n_rollout_threads<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># shape = (4, 54)</span>
<span class="token comment"># 指定3个智能体</span>
share_obs <span class="token operator">=</span> np<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>share_obs<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>repeat<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_agents<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment"># shape = (4, 3, 54)</span></code></pre>

<p>在share_obs中会将n&#x3D;3个智能体的obs叠加在一起作为share_obs。</p>
<ul>
<li><code>collect()</code>采用<code>rollout</code>方式采样数据</li>
</ul>
<p>在onpolicy&#x2F;runner&#x2F;shared&#x2F;mpe_runner.py中的的collect函数中，调用<code>self.trainer.prep_rollout()</code>函数将actor和critic都设置为<code>eval()</code>格式,然后用<code>np.concatenate()</code>函数将并行的环境的数据拼接在一起，这一步是将并行采样的那个纬度降掉:</p>
<pre class="language-python" data-language="python"><code class="language-python">value<span class="token punctuation">,</span> action<span class="token punctuation">,</span> action_log_prob<span class="token punctuation">,</span> rnn_states<span class="token punctuation">,</span> rnn_states_critic \
    <span class="token operator">=</span> self<span class="token punctuation">.</span>trainer<span class="token punctuation">.</span>policy<span class="token punctuation">.</span>get_actions<span class="token punctuation">(</span>np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span>self<span class="token punctuation">.</span><span class="token builtin">buffer</span><span class="token punctuation">.</span>share_obs<span class="token punctuation">[</span>step<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                            np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span>self<span class="token punctuation">.</span><span class="token builtin">buffer</span><span class="token punctuation">.</span>obs<span class="token punctuation">[</span>step<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                            np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span>self<span class="token punctuation">.</span><span class="token builtin">buffer</span><span class="token punctuation">.</span>rnn_states<span class="token punctuation">[</span>step<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment"># ?</span>
                            np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span>self<span class="token punctuation">.</span><span class="token builtin">buffer</span><span class="token punctuation">.</span>rnn_states_critic<span class="token punctuation">[</span>step<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                            np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span>self<span class="token punctuation">.</span><span class="token builtin">buffer</span><span class="token punctuation">.</span>masks<span class="token punctuation">[</span>step<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>

<p>将数据传入总的MAPPO策略网络R_MAPPOPolicy(onpolicy&#x2F;algorithms&#x2F;r_mappo&#x2F;algorithm&#x2F;rMAPPOPolicy.py)中去获取一个时间步的数据。在get_actions()里面调用actor去获取动作以及动作的对数概率，critic网络去获取对于cent_obs的状态值函数的输出：</p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token comment"># 调用actor去获取动作和动作的对数概率                                      </span>
actions<span class="token punctuation">,</span> action_log_probs<span class="token punctuation">,</span> rnn_states_actor <span class="token operator">=</span> self<span class="token punctuation">.</span>actor<span class="token punctuation">(</span>obs<span class="token punctuation">,</span>rnn_states_actor<span class="token punctuation">,</span> masks<span class="token punctuation">,</span> available_actions<span class="token punctuation">,</span> deterministic<span class="token punctuation">)</span></code></pre>

<p>在这里obs的shape是(4*3, 18),输出actions和action_log_probs的shape都为(12,1).</p>
<pre class="language-python" data-language="python"><code class="language-python">values<span class="token punctuation">,</span> rnn_states_critic <span class="token operator">=</span> self<span class="token punctuation">.</span>critic<span class="token punctuation">(</span>cent_obs<span class="token punctuation">,</span> rnn_states_critic<span class="token punctuation">,</span> masks<span class="token punctuation">)</span>   <span class="token comment"># 调用critic去对动作打分，得到values</span></code></pre>

<p>cent_obs’s shape is (5*2, 14),values’s shape is (12,1),and rnn_states’s shape is (12, 1, 64).</p>
<pre class="language-python" data-language="python"><code class="language-python">values <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>np<span class="token punctuation">.</span>split<span class="token punctuation">(</span>_t2n<span class="token punctuation">(</span>value<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>n_rollout_threads<span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment"># 将value转化成4层3行1列的数据</span>
actions <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>np<span class="token punctuation">.</span>split<span class="token punctuation">(</span>_t2n<span class="token punctuation">(</span>action<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>n_rollout_threads<span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment"># 这action转化成4层3行1列的数据</span>
action_log_probs <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>np<span class="token punctuation">.</span>split<span class="token punctuation">(</span>_t2n<span class="token punctuation">(</span>action_log_prob<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>n_rollout_threads<span class="token punctuation">)</span><span class="token punctuation">)</span>
rnn_states <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>np<span class="token punctuation">.</span>split<span class="token punctuation">(</span>_t2n<span class="token punctuation">(</span>rnn_states<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>n_rollout_threads<span class="token punctuation">)</span><span class="token punctuation">)</span>
rnn_states_critic <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>np<span class="token punctuation">.</span>split<span class="token punctuation">(</span>_t2n<span class="token punctuation">(</span>rnn_states_critic<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>n_rollout_threads<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
actions_env <span class="token operator">=</span> np<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>np<span class="token punctuation">.</span>eye<span class="token punctuation">(</span>self<span class="token punctuation">.</span>envs<span class="token punctuation">.</span>action_space<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>n<span class="token punctuation">)</span><span class="token punctuation">[</span>actions<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token comment"># 5维 (4, 3, 5)</span></code></pre>

<p>最后将(<code>12 , 1</code>)的<code>actions</code>转换成(<code>4, 3, 1</code>)的形式，方便之后并行送到并行的环境中去，作者这里还将动作进行了<code>one-hot</code>编码，最后变成了(<code>4, 3, 5</code>)的形式送入到环境中去。</p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token comment"># Obser reward and next obs</span>
obs<span class="token punctuation">,</span> rewards<span class="token punctuation">,</span> dones<span class="token punctuation">,</span> infos <span class="token operator">=</span> self<span class="token punctuation">.</span>envs<span class="token punctuation">.</span>step<span class="token punctuation">(</span>actions_env<span class="token punctuation">)</span>
data <span class="token operator">=</span> obs<span class="token punctuation">,</span> rewards<span class="token punctuation">,</span> dones<span class="token punctuation">,</span> infos<span class="token punctuation">,</span> values<span class="token punctuation">,</span> actions<span class="token punctuation">,</span> action_log_probs<span class="token punctuation">,</span> rnn_states<span class="token punctuation">,</span> rnn_states_critic
<span class="token comment"># insert data into buffer</span>
self<span class="token punctuation">.</span>insert<span class="token punctuation">(</span>data<span class="token punctuation">)</span></code></pre>

<p>环境下一次输出的<code>obs</code>还是(<code>4, 3, 18</code>)的形式，之后调<code>insert</code>方法将数据添加到<code>buffer</code>里面，在<code>insert</code>方法里面会将局部观测构造一个全局观测<code>share_obs</code>其shape&#x3D;(<code>4, 3, 54</code>)出来：</p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">insert</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>
    obs<span class="token punctuation">,</span> rewards<span class="token punctuation">,</span> dones<span class="token punctuation">,</span> infos<span class="token punctuation">,</span> values<span class="token punctuation">,</span> actions<span class="token punctuation">,</span> action_log_probs<span class="token punctuation">,</span> rnn_states<span class="token punctuation">,</span> rnn_states_critic <span class="token operator">=</span> data
    rnn_states<span class="token punctuation">[</span>dones <span class="token operator">==</span> <span class="token boolean">True</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token punctuation">(</span>dones <span class="token operator">==</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>recurrent_N<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
    rnn_states_critic<span class="token punctuation">[</span>dones <span class="token operator">==</span> <span class="token boolean">True</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token punctuation">(</span>dones <span class="token operator">==</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">*</span>self<span class="token punctuation">.</span><span class="token builtin">buffer</span><span class="token punctuation">.</span>rnn_states_critic<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
    masks <span class="token operator">=</span> np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>n_rollout_threads<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_agents<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
    masks<span class="token punctuation">[</span>dones <span class="token operator">==</span> <span class="token boolean">True</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token punctuation">(</span>dones <span class="token operator">==</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
    <span class="token keyword">if</span> self<span class="token punctuation">.</span>use_centralized_V<span class="token punctuation">:</span>
        share_obs <span class="token operator">=</span> obs<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>self<span class="token punctuation">.</span>n_rollout_threads<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        share_obs <span class="token operator">=</span> np<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>share_obs<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>repeat<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_agents<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        share_obs <span class="token operator">=</span> obs
    self<span class="token punctuation">.</span><span class="token builtin">buffer</span><span class="token punctuation">.</span>insert<span class="token punctuation">(</span>share_obs<span class="token punctuation">,</span> obs<span class="token punctuation">,</span> rnn_states<span class="token punctuation">,</span> rnn_states_critic<span class="token punctuation">,</span> actions<span class="token punctuation">,</span> action_log_probs<span class="token punctuation">,</span> values<span class="token punctuation">,</span> rewards<span class="token punctuation">,</span> masks<span class="token punctuation">)</span></code></pre>

<p>上述过程循环迭代<code>self.episode_length=100</code>次。</p>
<h2 id="训练流程"><a href="#训练流程" class="headerlink" title="训练流程"></a>训练流程</h2><ul>
<li>计算优势函数</li>
</ul>
<p>在训练之前，首先调用<code>self.compute()</code>函数计算<code>episode</code>的折扣回报，在计算折扣回报之前，先算这个<code>episode</code>最后一个状态的状态值函数<code>next_values</code>，其<code>shape=(12, 1)</code>然后调用<code>compute_returns</code>函数计算折扣回报:</p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">compute</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 计算这个episode的折扣回报，先用rMAPPOPolicy.py里面的get_values计算一下next_values</span>
    <span class="token triple-quoted-string string">"""Calculate returns for the collected data."""</span>
    self<span class="token punctuation">.</span>trainer<span class="token punctuation">.</span>prep_rollout<span class="token punctuation">(</span><span class="token punctuation">)</span>
    next_values <span class="token operator">=</span> self<span class="token punctuation">.</span>trainer<span class="token punctuation">.</span>policy<span class="token punctuation">.</span>get_values<span class="token punctuation">(</span>np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span>self<span class="token punctuation">.</span><span class="token builtin">buffer</span><span class="token punctuation">.</span>share_obs<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                             np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span>self<span class="token punctuation">.</span><span class="token builtin">buffer</span><span class="token punctuation">.</span>rnn_states_critic<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                             np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span>self<span class="token punctuation">.</span><span class="token builtin">buffer</span><span class="token punctuation">.</span>masks<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    next_values <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>np<span class="token punctuation">.</span>split<span class="token punctuation">(</span>_t2n<span class="token punctuation">(</span>next_values<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>n_rollout_threads<span class="token punctuation">)</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span><span class="token builtin">buffer</span><span class="token punctuation">.</span>compute_returns<span class="token punctuation">(</span>next_values<span class="token punctuation">,</span> self<span class="token punctuation">.</span>trainer<span class="token punctuation">.</span>value_normalizer<span class="token punctuation">)</span>  <span class="token comment"># 折扣回报的的计算方式</span></code></pre>

<p>有了数据之后就可以开始计算<strong>折扣回报</strong>了（在这里有采用<code>gae</code>算折扣回报的方式，并且有将<code>value</code>做<code>normalizer</code>）。<code>compute_returns</code>函数在<code>onpolicy/utils/shared_buffer.py</code> 中，核心代码如下：</p>
<pre class="language-python" data-language="python"><code class="language-python">self<span class="token punctuation">.</span>value_preds<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> next_value
gae <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">for</span> step <span class="token keyword">in</span> <span class="token builtin">reversed</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>rewards<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token keyword">if</span> self<span class="token punctuation">.</span>_use_popart <span class="token keyword">or</span> self<span class="token punctuation">.</span>_use_valuenorm<span class="token punctuation">:</span>
    delta <span class="token operator">=</span> self<span class="token punctuation">.</span>rewards<span class="token punctuation">[</span>step<span class="token punctuation">]</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>gamma <span class="token operator">*</span> value_normalizer<span class="token punctuation">.</span>denormalize<span class="token punctuation">(</span>
      self<span class="token punctuation">.</span>value_preds<span class="token punctuation">[</span>step <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>masks<span class="token punctuation">[</span>step <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span> \ 
    <span class="token operator">-</span> value_normalizer<span class="token punctuation">.</span>denormalize<span class="token punctuation">(</span>self<span class="token punctuation">.</span>value_preds<span class="token punctuation">[</span>step<span class="token punctuation">]</span><span class="token punctuation">)</span>
    gae <span class="token operator">=</span> delta <span class="token operator">+</span> self<span class="token punctuation">.</span>gamma <span class="token operator">*</span> self<span class="token punctuation">.</span>gae_lambda <span class="token operator">*</span> self<span class="token punctuation">.</span>masks<span class="token punctuation">[</span>step <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> gae
    self<span class="token punctuation">.</span>returns<span class="token punctuation">[</span>step<span class="token punctuation">]</span> <span class="token operator">=</span> gae <span class="token operator">+</span> value_normalizer<span class="token punctuation">.</span>denormalize<span class="token punctuation">(</span>self<span class="token punctuation">.</span>value_preds<span class="token punctuation">[</span>step<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>

<p>算完折扣回报后调用<code>self.train()</code>函数进行训练:</p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 算完折扣回报之后调用self.train()函数进行训练</span>
  <span class="token triple-quoted-string string">"""Train policies with data in buffer. """</span>
  self<span class="token punctuation">.</span>trainer<span class="token punctuation">.</span>prep_training<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 将网络设置为train（）的格式</span>
  train_infos <span class="token operator">=</span> self<span class="token punctuation">.</span>trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span>self<span class="token punctuation">.</span><span class="token builtin">buffer</span><span class="token punctuation">)</span>      
  self<span class="token punctuation">.</span><span class="token builtin">buffer</span><span class="token punctuation">.</span>after_update<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 将buffer的第一个元素设置为其episode最后的一个元素</span>
  <span class="token keyword">return</span> train_infos</code></pre>

<p>在<code>self.trainer.train(self.buffer)</code>函数中先基于数据，计算优势函数(优势函数是针对全局的观测信息所得到的)：</p>
<pre class="language-python" data-language="python"><code class="language-python">advantages <span class="token operator">=</span> <span class="token builtin">buffer</span><span class="token punctuation">.</span>returns<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>value_normalizer<span class="token punctuation">.</span>denormalize<span class="token punctuation">(</span><span class="token builtin">buffer</span><span class="token punctuation">.</span>value_preds<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
advantages_copy <span class="token operator">=</span> advantages<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
advantages_copy<span class="token punctuation">[</span><span class="token builtin">buffer</span><span class="token punctuation">.</span>active_masks<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">0.0</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>nan
mean_advantages <span class="token operator">=</span> np<span class="token punctuation">.</span>nanmean<span class="token punctuation">(</span>advantages_copy<span class="token punctuation">)</span> <span class="token comment"># float, shape = (1)</span>
std_advantages <span class="token operator">=</span> np<span class="token punctuation">.</span>nanstd<span class="token punctuation">(</span>advantages_copy<span class="token punctuation">)</span>  <span class="token comment"># float, shape = (1)</span>
advantages <span class="token operator">=</span> <span class="token punctuation">(</span>advantages <span class="token operator">-</span> mean_advantages<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>std_advantages <span class="token operator">+</span> <span class="token number">1e-5</span><span class="token punctuation">)</span></code></pre>

<p>然后从<code>buffer</code>中采样数据，把线程、智能体的纬度全部降掉</p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token comment"># 从 data_generator 中采样</span>
<span class="token keyword">for</span> sample <span class="token keyword">in</span> data_generator<span class="token punctuation">:</span>
  <span class="token comment"># 进行一次 PPO 更新</span>
  value_loss<span class="token punctuation">,</span> critic_grad_norm<span class="token punctuation">,</span> policy_loss<span class="token punctuation">,</span> dist_entropy<span class="token punctuation">,</span> actor_grad_norm<span class="token punctuation">,</span> imp_weights \
                        <span class="token operator">=</span> self<span class="token punctuation">.</span>ppo_update<span class="token punctuation">(</span>sample<span class="token punctuation">,</span> update_actor<span class="token punctuation">)</span></code></pre>

<p><code>ppo_update</code>函数大体流程是:</p>
<ol>
<li>从buffer中抽样建立sample</li>
<li>将抽样的数据传递给rMAPPOPolicy.py中的evaluate_actions函数，得到 values, action_log_probs, dist_entropy</li>
<li>计算actor的loss</li>
<li>计算critic的loss</li>
</ol>
<p>然后在<code>onpolicy/algorithms/r_mappo/r_mappo.py</code>中</p>
<pre class="language-python" data-language="python"><code class="language-python">share_obs_batch<span class="token punctuation">,</span> obs_batch<span class="token punctuation">,</span> rnn_states_batch<span class="token punctuation">,</span> rnn_states_critic_batch<span class="token punctuation">,</span> actions_batch<span class="token punctuation">,</span>\ 
        value_preds_batch<span class="token punctuation">,</span> return_batch<span class="token punctuation">,</span>masks_batch<span class="token punctuation">,</span>active_masks_batch<span class="token punctuation">,</span>old_action_log_probs_batch<span class="token punctuation">,</span> \
        adv_targ<span class="token punctuation">,</span> available_actions_batch <span class="token operator">=</span> sample</code></pre>

<p>拿到采样之后的数据，把<code>obs</code>送给<code>actor</code>网络，得到<code>action_log_probs</code>, <code>dist_entropy</code>。把<code>cent_obs</code>送到<code>critic</code>得到新的<code>values</code>。</p>
<ul>
<li>计算actor的loss</li>
</ul>
<p>在<code>ppo_update()</code>中，利用新老动作的概率分布和优势函数之后就可以更新<code>actor</code>网络了：</p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token comment"># actor update</span>
imp_weights <span class="token operator">=</span> torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>action_log_probs <span class="token operator">-</span> old_action_log_probs_batch<span class="token punctuation">)</span>

surr1 <span class="token operator">=</span> imp_weights <span class="token operator">*</span> adv_targ
surr2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span>imp_weights<span class="token punctuation">,</span> <span class="token number">1.0</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>clip_param<span class="token punctuation">,</span> <span class="token number">1.0</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>clip_param<span class="token punctuation">)</span> <span class="token operator">*</span> adv_targ
policy_action_loss <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token operator">-</span>torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span>surr1<span class="token punctuation">,</span> surr2<span class="token punctuation">)</span><span class="token punctuation">,</span>
                                             dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>
                                             keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token operator">*</span> active_masks_batch<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> active_masks_batch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span>policy_loss <span class="token operator">-</span> dist_entropy <span class="token operator">*</span> self<span class="token punctuation">.</span>entropy_coef<span class="token punctuation">)</span><span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre>

<ul>
<li>计算critic的loss</li>
</ul>
<p>新的<code>value</code>和老的<code>value_preds_batch</code>和计算的<code>return_batch</code>送到<code>onpolicy/algorithms/r_mappo/r_mappo.py</code>文件的<code>cal_value_loss</code>函数中去计算<code>critic</code>的<code>loss</code>：</p>
<pre class="language-python" data-language="python"><code class="language-python">value_loss <span class="token operator">=</span> self<span class="token punctuation">.</span>cal_value_loss<span class="token punctuation">(</span>values<span class="token punctuation">,</span> value_preds_batch<span class="token punctuation">,</span> return_batch<span class="token punctuation">,</span> active_masks_batch<span class="token punctuation">)</span></code></pre>

<p>and then</p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token comment"># 对value做一个clipped</span>
value_pred_clipped <span class="token operator">=</span> value_preds_batch <span class="token operator">+</span> <span class="token punctuation">(</span>values <span class="token operator">-</span> value_preds_batch<span class="token punctuation">)</span><span class="token punctuation">.</span>clamp<span class="token punctuation">(</span><span class="token operator">-</span>self<span class="token punctuation">.</span>clip_param<span class="token punctuation">,</span> self<span class="token punctuation">.</span>clip_param<span class="token punctuation">)</span>
<span class="token comment"># 然后计算误差的clip</span>
error_clipped <span class="token operator">=</span> return_batch <span class="token operator">-</span> value_pred_clipped
error_original <span class="token operator">=</span> return_batch <span class="token operator">-</span> values
<span class="token comment"># 然后直接计算loss</span>
value_loss_clipped <span class="token operator">=</span> mse_loss<span class="token punctuation">(</span>error_clipped<span class="token punctuation">)</span>
value_loss_original <span class="token operator">=</span> mse_loss<span class="token punctuation">(</span>error_original<span class="token punctuation">)</span>
<span class="token comment"># 算出loss之后反向传播即可</span>
<span class="token punctuation">(</span>value_loss <span class="token operator">*</span> self<span class="token punctuation">.</span>value_loss_coef<span class="token punctuation">)</span><span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre>

<h2 id="实验设计"><a href="#实验设计" class="headerlink" title="实验设计"></a>实验设计</h2><p>以下实验来源于Policy Regularization via Noisy Advantage Values for<br>Cooperative Multi-agent Actor-Critic methods(arXiv:2106.14334v13 )</p>
<h3 id="算法表现对比"><a href="#算法表现对比" class="headerlink" title="算法表现对比"></a>算法表现对比</h3><p>首先展示了论文介绍的算法以及其对比算法在SMAC各种场景下的胜率,将自己算法效果好于或者等于其他算法的效果的场景下的胜率进行加粗展示:</p>
<p><img src="http://cdn.leafii.top/img/image-20221031140635091.png" alt="image-20221031140635091" loading="lazy"></p>
<p>论文对该表的解释:</p>
<blockquote>
<p>表 2 中的实验结果表明 (1) NV-MAPPO 在大多数困难场景 2 上的性能显着超过 MAPPO，例如 5m_vs_6m (+65%)、走廊 (+97%)、6h_vs_8z (+87%) 和 3s5z_vs_3s6z (+31%)。 （2）NV-IPPO在Super Hard场景3s5z_vs_3s6z（96%）和6h_vs_8z（94%）中取得了超高的胜率；我们推测这是因为噪声还可以防止 IPPO 由于非平稳性而过拟合。 (3) NV-MAPPO 在硬场景上的平均性能优于 Fine-tuned QMIX 和 MAPPO-FP。 (4) 我们在附录 B.1 中比较了 MAPG 和 NV-MAPG，发现 NV-MAPG 的性能也明显优于 MAPG。</p>
<p>所有这些结果表明，噪声值函数在实际任务中效果很好。由于我们使用 Fine-tuned QMIX [5] 作为基线，QMIX 的中位测试获胜率明显优于过去文献中的实验结果 [14, 19, 20, 26]。至此，NV-MAPPO 和 NV-IPPO 在 SMAC 中共同实现了 SOTA。具体来说，NV-IPPO（适用于 3s5z_vs_3s6z 和 6h_vs_8z）和 NVMAPPO（适用于其他硬场景）在所有硬场景中的平均胜率为 97%。</p>
</blockquote>
<h3 id="NA-MAPPO和NV-MAPPO的对比"><a href="#NA-MAPPO和NV-MAPPO的对比" class="headerlink" title="NA-MAPPO和NV-MAPPO的对比"></a>NA-MAPPO和NV-MAPPO的对比</h3><p>接着又对NA-MAPPO和NV-MAPPO进行了对比,并对NA-MAPPO算法胜率的较大方差进行了解释,算法胜率的方差可以显示出算法的稳定性.</p>
<p><img src="http://cdn.leafii.top/img/image-20221031141622734.png" alt="image-20221031141622734" loading="lazy"></p>
<blockquote>
<p>如图4所示，我们发现噪声优势方法在某些情况下可能会损害算法的稳定性，即噪声优势方法的胜率有很大的方差。我们推测，可能是显性噪声破坏了政策梯度的原有方向。 但是，在smac的某些困难情况下，NA-MAPPO的性能仍可与NV-MAPPO媲美; 我们注意到NA-MAPPO非常容易实现。所有这些结果表明，噪声优势值确实改善了vanilla MAPPO的性能。</p>
</blockquote>
<p>然后对NV-MAPPO的噪声值函数如何影响性能进行进一步的实验分析:</p>
<p><img src="http://cdn.leafii.top/img/image-20221031141816194.png" alt="image-20221031141816194" loading="lazy"></p>
<blockquote>
<p>接下来，我们对NV-MAPPO的噪声值函数如何影响性能进行进一步的实验分析。我们在图 5 中展示了一些 Hard 场景下代理维度中值函数𝑣𝑖的标准差。我们发现，<strong>在某些场景中，𝑣𝑖 的大方差意味着 NV-MAPPO 在这些场景中相对于 vanilla MAPPO 的性能提升也很大</strong>，如3s5z_vs_3s6z和6h_vs_8z（见图5和图4）。该定律表明，NV-MAPPO 的性能提升确实来自价值函数的噪声扰动。</p>
</blockquote>
<p>最后分析了噪声值函数在3𝑠5𝑧_𝑣𝑠_3𝑠6𝑧场景下对策略熵的影响</p>
<p><img src="http://cdn.leafii.top/img/image-20221031142025436.png" alt="image-20221031142025436" loading="lazy"></p>
<blockquote>
<p>最后分析了噪声值函数对方案3 𝑠 5 𝑧 _ 𝑣𝑠 _ 3 𝑠 6 𝑧 策略熵的影响。如图6所示，vanilla MAPPO策略的熵迅速下降，并落入局部最优解，因此胜率始终为零。对于NV-MAPPO，我们平滑了采样的优势值，并且噪声可以防止策略过拟合，因此策略的熵会更加谨慎地降低。</p>
</blockquote>
<h3 id="策略熵和好奇心探索的异同"><a href="#策略熵和好奇心探索的异同" class="headerlink" title="策略熵和好奇心探索的异同"></a>策略熵和好奇心探索的异同</h3><p>policy entropy，从动作空间的角度出发，尽可能探索各种不同的动作，使得策略熵最大化，隐含着各种状态空间也会被探索到。policy entropy依据action的Q值来分配探索的概率，而不是$\epsilon-greedy$中固定概率$\epsilon&#x2F;|A|$探索较低Q值的action.另外policy entropy不简单是一个正则项,有另一个完整的RL框架来描述它,参见<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/57210858">此链接</a></p>
<p>curiosity，从状态空间的角度出发，尽可能探索环境的状态转移方式，并把未知的状态转移方式作为内部rewards，以期改变agent的行为。参考<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/58923482">此链接</a></p>
<p>应用上，policy entropy适合连续动作空间，如操作机械臂等，得到的策略更鲁棒；curiosity适合sparse rewards的问题，如走迷宫，它能为训练提供更丰富的学习信号。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol>
<li>多智能体强化学习(二) MAPPO算法详解 <a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_39059031/article/details/117283800">https://blog.csdn.net/weixin_39059031/article/details/117283800</a></li>
<li>多智能体强化学习MAPPO源代码解读 <a target="_blank" rel="noopener" href="https://blog.csdn.net/onlyyyyyyee/article/details/118888711">https://blog.csdn.net/onlyyyyyyee/article/details/118888711</a></li>
<li>如何理解强化学习中的”好奇心探索”和”策略熵”的异同？ - bigiceberg M的回答 - 知乎 <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/311267842/answer/631757642">https://www.zhihu.com/question/311267842/answer/631757642</a></li>
</ol>
</div></section><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>Leafii</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="2022/09/30/MAPPO源代码分析/" title="MAPPO源代码分析">2022/09/30/MAPPO源代码分析/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>本博客所有文章除特别声明外，均默认采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0 "><svg class="icon"><use xlink:href="#icon-creative-commons-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-by-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-nc-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-sa-line"></use></svg></a> 许可协议。</li></ul></article><div class="post-nav"><div class="post-nav-item"><a class="post-nav-prev" href="../../../11/04/%E5%9C%A8macOS%E4%B8%8A%E4%B8%BA%E8%87%AA%E5%B7%B1%E7%9A%84Latex%E5%AE%89%E8%A3%85LaTeX-sty%E6%96%87%E4%BB%B6/" rel="prev" title="在macOS上为自己的Latex安装LaTeX.sty文件"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-left-s-line"></use></svg><span class="post-nav-text">在macOS上为自己的Latex安装LaTeX.sty文件</span></a></div><div class="post-nav-item"><a class="post-nav-next" href="../../20/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0_PPO%E7%AE%97%E6%B3%95(Proximal%20Policy%20Optimization)/" rel="next" title="强化学习_PPO算法(Proximal Policy Optimization)"><span class="post-nav-text">强化学习_PPO算法(Proximal Policy Optimization)</span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-right-s-line"></use></svg></a></div></div></div><div class="hty-card" id="comment"></div></main><footer class="sidebar-translate" id="footer"><div class="copyright"><span>&copy; 2019 – 2023 </span><span class="with-love" id="animate"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-cloud-line"></use></svg></span><span class="author"> Leafii</span></div><div class="powered"><span>由 <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a> 驱动 v6.2.0</span><span class="footer-separator">|</span><span>主题 - <a rel="noopener" href="https://github.com/YunYouJun/hexo-theme-yun" target="_blank"><span>Yun</span></a> v1.9.3</span></div></footer><a class="hty-icon-button" id="back-to-top" aria-label="back-to-top" href="#"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-up-s-line"></use></svg><svg class="progress-circle-container" viewBox="0 0 100 100"><circle class="progress-circle" id="progressCircle" cx="50" cy="50" r="48" fill="none" stroke="#0078E7" stroke-width="2" stroke-linecap="round"></circle></svg></a><a class="popup-trigger hty-icon-button icon-search" id="search" href="javascript:;" title="搜索"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-search-line"></use></svg></span></a><script>window.addEventListener("DOMContentLoaded", () => {
  // Handle and trigger popup window
  document.querySelector(".popup-trigger").addEventListener("click", () => {
    document.querySelector(".popup").classList.add("show");
    setTimeout(() => {
      document.querySelector(".search-input").focus();
    }, 100);
  });

  // Monitor main search box
  const onPopupClose = () => {
    document.querySelector(".popup").classList.remove("show");
  };

  document.querySelector(".popup-btn-close").addEventListener("click", () => {
    onPopupClose();
  });

  window.addEventListener("keyup", event => {
    if (event.key === "Escape") {
      onPopupClose();
    }
  });
});
</script><script src="../../../../js/search/local-search.js" defer type="module"></script><div class="popup search-popup"><div class="search-header"><span class="popup-btn-close close-icon hty-icon-button"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-close-line"></use></svg></span></div><div class="search-input-container"><input class="search-input" id="local-search-input" type="text" placeholder="搜索..." value=""></div><div id="local-search-result"></div></div><script>function initMourn() {
  const date = new Date();
  const today = (date.getMonth() + 1) + "-" + date.getDate()
  const mourn_days = ["4-4","9-18"]
  if (mourn_days.includes(today)) {
    document.documentElement.style.filter = "grayscale(1)";
  }
}
initMourn();</script></div></body></html>